---
title: HW6_Conditional_Duffsion_Model

---

# æ–‡å­—æ¢ä»¶å¼åœ–åƒç”Ÿæˆè¨“ç·´ç¨‹å¼

æœ¬å°ˆæ¡ˆç‚ºä¸€å€‹åŸºæ–¼ [`Diffusers`](https://github.com/huggingface/diffusers) Text Conditional Duffsion Modelï¼Œçµåˆé è¨“ç·´çš„ CLIPï¼ˆæ–‡å­—ç·¨ç¢¼å™¨ï¼‰ã€VAE ä»¥åŠ UNet æ¨¡å‹ï¼Œè¨“ç·´ä¸€å€‹èƒ½æ ¹æ“š prompt ç”Ÿæˆå°æ‡‰åœ–ç‰‡çš„ Diffusion æ¨¡å‹ã€‚

## ä½¿ç”¨æ–¹å¼

```
.
â”œâ”€â”€ train.py              # ä¸»è¨“ç·´ç¨‹å¼
â”œâ”€â”€ train_info.json       # åŒ…å«åœ–ç‰‡å°æ‡‰çš„æè¿°è³‡æ–™
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ ckpt_last/        # å„²å­˜æ¨¡å‹ checkpoint
â”‚   â””â”€â”€ samples_last/     # å„²å­˜æ¯æ¬¡ç”Ÿæˆåœ–ç‰‡çµæœ
```

---

## å»ºç«‹ç’°å¢ƒ


```bash
pip install -r requirements.txt
```

---

## è¨“ç·´æ–¹å¼

åŸ·è¡Œä¸»è¨“ç·´ç¨‹å¼ï¼š

```bash
python train.py
```

è‹¥è¦æ¥çºŒæŸå€‹ checkpoint è¨“ç·´ï¼Œå¯ä»¥è¨­å®š `ckpt_path` çš„è·¯å¾‘ï¼Œæœƒæ¥çºŒè¨“ç·´ã€‚

### è¨“ç·´æµç¨‹ï¼š

1. è¼‰å…¥é è¨“ç·´æ¨¡å‹ï¼š

   * `CLIPTextModel` CLIPï¼ˆ`openai/clip-vit-base-patch32`ï¼‰
   * `AutoencoderKL` VAEï¼ˆ`CompVis/stable-diffusion-v1-4/vae`ï¼‰
2. åˆå§‹åŒ– UNet æ¨¡å‹æ¶æ§‹
3. è¨“ç·´ UNet é æ¸¬åŠ å™ªè²çš„ latent
4. ä½¿ç”¨ bfloat16 æ··åˆç²¾åº¦ï¼ˆAMPï¼‰èˆ‡ gradient accumulation steps é€²è¡Œè¨“ç·´
5. `eval_freq` æ¯ 500 steps æœƒä½¿ç”¨ä¸€äº›å›ºå®šæ–‡å­—æè¿°ç”Ÿæˆåœ–ç‰‡åšè©•ä¼°
6. `save_freq` æ¯ 500 steps å„²å­˜æ¨¡å‹æ¬Šé‡

### é æ¸¬åœ–åƒç”Ÿæˆæµç¨‹

ç•¶ç„¶å¯ä»¥ï¼Œä»¥ä¸‹æ˜¯é‡å°ä½ æä¾›çš„ `generate.py`ï¼Œç”¨åŒæ¨£æ ¼å¼æ•´ç†çš„ **æ¨è«–èˆ‡åœ–ç‰‡ç”Ÿæˆæµç¨‹**ï¼š

---

## ğŸ§ª æ¨è«–èˆ‡åœ–ç‰‡ç”Ÿæˆæµç¨‹

1. è¼‰å…¥é è¨“ç·´æ¨¡å‹ï¼š

   * `CLIPTextModel` CLIPï¼ˆ`openai/clip-vit-base-patch32`ï¼‰
   * `AutoencoderKL` VAEï¼ˆ`CompVis/stable-diffusion-v1-4/vae`ï¼‰

2. è¼‰å…¥è¨“ç·´å®Œæˆçš„ UNet æ¬Šé‡ï¼ˆ`UNet2DConditionModel`ï¼‰ï¼Œå¯è¨­å®š `stage` åƒæ•¸é¸æ“‡è¦ç”Ÿæˆçš„æ˜¯æ ¹æ“šå“ªå€‹ step çš„ checkpoint
3. ä½¿ç”¨ `test.json` è®€å–æ¯ç­†æ¸¬è©¦è³‡æ–™ä¸­çš„ `text_prompt`
4. å»ºç«‹ classifier-free guidance æ¢ä»¶èˆ‡ç„¡æ¢ä»¶çš„å‘é‡è¼¸å…¥
5. ä½¿ç”¨ `DDIMScheduler` é€²è¡Œ 50 æ­¥ inference é‚„åŸ latent åœ–åƒ
6. å°‡é‚„åŸå¾Œçš„ latent ç¶“ç”± VAE è§£ç¢¼ä¸¦å„²å­˜ç‚º `.png` åœ–ç‰‡æ–¼ `/outputs/ckpt_last/unet_{stage}`

---

## æ¨¡å‹æ¶æ§‹è‡ªå®šç¾©

UNet æ¶æ§‹ï¼š

```python
unet = UNet2DConditionModel(
        sample_size=32,
        in_channels=4,
        out_channels=4,
        block_out_channels=[256, 384, 512, 768],
        layers_per_block=2,
        down_block_types=[
            "CrossAttnDownBlock2D",
            "CrossAttnDownBlock2D",
            "CrossAttnDownBlock2D",
            "DownBlock2D"
        ],
        up_block_types=[
            "UpBlock2D",
            "CrossAttnUpBlock2D",
            "CrossAttnUpBlock2D",
            "CrossAttnUpBlock2D"
        ],
        cross_attention_dim=512,
        attention_head_dim=16
    ).to(device)
```

---

## é è¨“ç·´æ¬Šé‡å„²å­˜æ ¼å¼

ä½¿ç”¨ `safetensors` æ ¼å¼å„²å­˜æ–¼ï¼š

```
outputs/ckpt_last/unet_sch_XXXX/diffusion_pytorch_model.safetensors
```

## è³‡æ–™å¤¾çµæ§‹
```
hw6_313707045.zip
â”œâ”€â”€ public_data/
â”‚   â”œâ”€â”€ sample_code/
â”‚   â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”‚   â”œâ”€â”€ ckpt_last/           # å„²å­˜æ¨¡å‹ä¹‹æ¬Šé‡è³‡æ–™å¤¾
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€unet_sch_XXXXX    # æ¨¡å‹æ¬Šé‡
â”‚   â”‚   â”‚   â”œâ”€â”€ samples_last/        # è¨“ç·´æ¸¬è©¦ç”Ÿæˆåœ–ç‰‡
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ test.json                # æ¸¬è©¦è³‡æ–™
â”‚   â”‚   â”œâ”€â”€ test.py                  # åœ–ç‰‡ç”Ÿæˆä¸»ç¨‹å¼
â”‚   â”‚   â”œâ”€â”€ train.py                 # è¨“ç·´ä¸»ç¨‹å¼
â”‚   â”œâ”€â”€ train/                       # è¨“ç·´ç”¨åœ–ç‰‡è³‡æ–™å¤¾
â”‚   â””â”€â”€ train_info.json              # è¨“ç·´åœ–åƒå°æ‡‰çš„æ–‡å­—æè¿°
â”œâ”€â”€ scoring_program/                 # è©•åˆ†ç”¨ç¨‹å¼
```

### Output é è¦½:
[![Result Preview](result_preview.png)](https://github.com/313707045FangShuo/Generative_AI/blob/6fdee652c4c90a5877f49d10ba7c7b8c3134911f/GAI_HW6_conditional_DiffusionModel/result_preview.png)

### ä½œæ¥­æ’å: 37/100
[![Competetion Result: 37th of 100](competetion_result.png)](https://github.com/313707045FangShuo/Generative_AI/blob/6fdee652c4c90a5877f49d10ba7c7b8c3134911f/GAI_HW6_conditional_DiffusionModel/competetion_result.png)
