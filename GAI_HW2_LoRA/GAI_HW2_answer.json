{"paper_id": "408", "abstract": "In the realm of generative models, few have achieved the heights of success as Generative Adversarial Networks (GANs), captivating the imagination with their ability to conjure images that rival the finest works of art. Yet, beneath this veneer of triumph lies a deeper truth: GANs often stumble when faced with the intricate dance of disconnected target distributions. This limitation, while well-documented, has left the broader implications of their latent space organization shrouded in mystery.  In this exploration, we embark on a journey to illuminate the latent space of GANs, drawing inspiration from the elegant principles of Gaussian isoperimetric inequalities. Our quest reveals that when GANs strive to minimize the perimeter of their generated samples relative to the target distribution, they inadvertently align themselves with the very essence of optimal partitions in Gaussian space. This revelation leads us to a pivotal conclusion: GANs that achieve this balance possess a latent space structure akin to a simplicial cluster, a configuration that not only enhances their precision but also sets them apart as global minimizers in the landscape of GAN performance.  Through a blend of theoretical rigor and empirical investigation, we unveil a novel upper bound on the precision of GANs, intricately tied to the number of modes in the target distribution. Moreover, we derive a lower bound, demonstrating that GANs with latent spaces organized as simplicial clusters attain this upper limit, their precision approaching an optimal state as the number of modes increases.  Our experimental findings further strengthen this narrative, illustrating how GANs tend to gravitate toward this optimal latent space structure across various image datasets. We also delve into the interplay of latent space dimensionality, overparametrization, and the characteristics of generated samples, revealing the intricate dance that governs GAN performance. In this exploration, we not only shed light on the latent space of GANs but also chart a course toward a deeper understanding of their potential, one that promises to reshape our expectations of what generative models can achieve."}
{"paper_id": "409", "abstract": "In the realm of causal inference, the quest to unravel the intricate tapestry of treatment effects from observational data is fraught with challenges. Traditionally, researchers have navigated this complexity through the lens of average treatment effects, often employing doubly-robust estimators that rely on well-calibrated models for both the expected outcome and the propensity score. Yet, the broader landscape of treatment effect estimation remains largely uncharted, particularly when it comes to the nuanced world of multiple treatments and continuously-valued dosages.  In this paper, we embark on a journey to explore the intricacies of representation learning within the context of treatment effect estimation. Our exploration is grounded in the pursuit of bounds that illuminate the generalization error of factual and counterfactual estimators, revealing that these bounds can be elegantly expressed through integral probability metrics. This insight leads us to a novel training objective for representation learning, one that is both computationally feasible and theoretically sound.  We put our proposed method to the test against established benchmarks, pitting it against a variety of neural network architectures that have been crafted for this very purpose. Our findings reveal a promising pathway forward, showcasing the potential of representation learning to enhance treatment effect estimation in more expansive and complex scenarios. For those eager to delve deeper, our code awaits in the appendix, ready to illuminate the path to new discoveries in this evolving field."}
{"paper_id": "410", "abstract": "In the realm of machine learning, the ascent of deep neural networks has been nothing short of meteoric, yet it is a journey fraught with challenges. As we delve into the intricacies of training these intricate models, we find ourselves grappling with the dual burdens of ever-increasing hardware demands and the specter of escalating energy consumption. This confluence of factors raises urgent questions: Are we on the brink of a technological impasse? Will the pursuit of cutting-edge research become a privilege reserved for the few, the wealthy, and the powerful?  In this exploration, we embark on a journey through the landscape of machine learning, tracing the evolution of hardware and its pivotal role in propelling the field forward. We then turn our attention to the concerns that have emerged within the machine learning community, particularly as they pertain to the realms of socioeconomics, science, and the environment. Our focus narrows to the implications of these issues within the context of applied machine learning in biology and chemistry.  Through a series of case studies, we illuminate the stark reality of the increasing costs associated with training deep neural networks. We examine the implications of these trends for researchers in academia and industry, particularly in the fields of chemistry and biology. Our findings reveal a troubling narrative: the dominance of a select few, predominantly from the tech sector, in the realm of high-profile research. This concentration of power and resources threatens to overshadow the contributions of scholars from other disciplines, such as chemistry and biology, who are eager to harness the transformative potential of machine learning.  As we conclude, we reflect on the urgent need for a collaborative effort among researchers, policymakers, and industry leaders to forge a path forward that ensures equitable access to the tools and knowledge of machine learning. Only then can we hope to unlock its full potential for the betterment of society as a whole."}
{"paper_id": "411", "abstract": "In the realm of deep learning, where the intricacies of neural networks often feel like an uncharted landscape, recent explorations have illuminated a path toward enhanced generalization through the lens of gradient regularization (GR). This technique, by penalizing the norm of the gradient itself, seeks to steer the training dynamics toward the coveted flat minima, promising greater generalization prowess. Yet, the theoretical underpinnings of this approach have remained shrouded in fog, leaving many to wonder about its true potential.  In this work, we embark on a journey to unravel these mysteries. First, we unveil a computational shortcut: the finite-difference method, a cost-effective means of approximating the gradient of the gradient, which proves to be more potent than its more established counterpart, double backpropagation. Our exploration reveals that employing a forward finite-difference GR not only enhances generalization but also benefits from an increasing gradient ascent step size.  But we do not stop there. We delve into the theoretical depths, providing a rigorous proof that demonstrates how GR possesses an implicit bias, guiding the learning process toward desirable solutions within the context of a diagonal linear network. This bias becomes more pronounced in the rich regime, a concept introduced by Woodworth et al. (2020), further enriching our understanding of GR's capabilities.  Moreover, we establish a fascinating connection between GR and two other innovative learning methods: sharpness-aware minimization and the flooding method. In doing so, we weave together the threads of these regularization techniques, creating a tapestry of understanding that illuminates the intricate relationships within the deep learning landscape.  Through this work, we aim to provide both practical insights and a robust theoretical framework, paving the way for future advancements in the field and inspiring further exploration into the depths of neural network optimization."}
{"paper_id": "412", "abstract": "In the realm of machine learning, where the arcane art of deep learning unfolds, a powerful tool emerges: the high-dimensional representations, or embeddings, conjured forth by deep neural networks. These embeddings, while formidable in their complexity—often residing in a vast, 512-dimensional space—serve as the lifeblood for numerous applications. Yet, in a twist of fate, it is the visualizations of these embeddings, such as the t-SNE plots, that are frequently shared with the world, illuminating pathways to understanding.   However, lurking in the shadows is a perilous threat: the property inference attack. This insidious assault allows cunning adversaries to extract sensitive global properties of a dataset, hidden within the very t-SNE plots deemed safe for public consumption. In our exploration, we embark on a journey to illuminate the vulnerabilities of these plots, employing a straightforward yet potent attack model. This model, trained on the intricate dance of t-SNE plots and their corresponding properties, proves remarkably adept at inferring the properties of new t-SNE plots, even when they are cloaked in the anonymity of public release.  Our findings, drawn from both classification and regression tasks, reveal a disturbing truth: our attack model can achieve an impressive accuracy of nearly 92% in predicting the proportion of males within the CelebA dataset, while the average regression error for precise proportions hovers at a mere 0.02. We delve into the reasons behind the lesser performance on other datasets and attributes, uncovering the complexities that weave through this intricate landscape. Moreover, we validate the robustness of our attack across various t-SNE density settings and the transferability to new datasets, even when the shadow and target models diverge.  To counteract these threats, we propose a simple yet effective defense: the introduction of noise into the t-SNE plots. While this measure proves effective in mitigating the attack, it invites a counter-strategy from adaptive adversaries. In this unfolding narrative of power and deception, we are left to ponder the delicate balance between revelation and protection in the realm of machine learning."}
{"paper_id": "413", "abstract": "In the realm of machine learning, where models are crafted with precision and care, a sinister force lurks in the shadows: backdoor attacks. These insidious threats can shatter the trust we place in our algorithms, manipulating their predictions with deceptive ease. Traditionally, attackers have relied on rare patterns—think stickers or unique phrases—as triggers, cleverly inserted into input data to sow confusion. However, this approach reveals itself too readily, allowing defenses to easily identify and mitigate the attack.  In this paper, we unveil a groundbreaking strategy for crafting triggers that are not only more potent but also far harder to detect. By delving into the data itself, we extract triggers from benign samples that are closely associated with the target class, creating a seamless blend that is nearly undetectable. Our experiments, conducted on four well-regarded datasets, reveal a remarkable enhancement in both the stealthiness and efficiency of our attacks. With fewer poisoned samples, we achieve superior performance, outmaneuvering existing defense mechanisms that struggle to keep pace with our innovative approach. In this new landscape, the balance of power shifts, as attackers find new ways to whisper their messages into the hearts of machines, undetected by the very defenses designed to protect them."}
{"paper_id": "414", "abstract": "In the realm of deep learning, where the quest for efficiency and performance is ever-present, network binarization emerges as a beacon of hope—a technique that shrinks the colossal parameters of deep neural networks down to mere bits, achieving a remarkable reduction in storage and acceleration through swift bitwise operations. Yet, as with all powerful tools, it is not without its challenges. The current landscape of network binarization research is fraught with perilous trends that threaten to undermine its potential for practical deployment. First, the focus on a narrow spectrum of learning tasks, primarily limited to image classification, obscures the broader architectural implications and the resilience of these models against data corruption. Second, the theoretical promises of efficiency often remain unfulfilled in the gritty reality of edge devices, as the practical training efficiency of these algorithms remains shrouded in mystery.  To navigate these treacherous waters, we introduce BiBench, a robust network Binarization Benchmark crafted to illuminate the path of comprehensive evaluation. Through BiBench, we embark on a thorough examination of 8 leading binarization algorithms across 9 diverse datasets, 13 esteemed neural architectures, 2 deployment libraries, 14 cutting-edge hardware chips, and a multitude of hyperparameter configurations. Our findings reveal critical insights: the underwhelming efficiency of binarized models in the wild, the often-unrealistic accuracy performance in the face of data corruption, and the overlooked training efficiency that plagues these algorithms in practice.  Armed with these revelations, we offer strategic recommendations for the design of binarization algorithms that truly stand ready for deployment in the real world. In this way, we aim not only to advance the field but also to pave the way for a future where binarization becomes a cornerstone of practical deep learning."}
{"paper_id": "415", "abstract": "In the realm of machine learning, the quest for understanding how deep neural networks navigate the intricate landscape of Out-Of-Distribution (OOD) samples has long been fraught with challenges. Traditional approaches have often relied on a disjointed, layer-wise analysis of scores, neglecting the profound interdependencies that exist as an input traverses the multifaceted architecture of a deep network. This oversight can lead to a loss of critical discriminative power when it comes to identifying samples that stray from the familiar.  In this paper, we embark on a new path, reimagining the problem of OOD detection through the lens of a functional trajectory. By conceptualizing the journey of an input sample through the layers of a neural network as a series of interconnected curves, we introduce a groundbreaking unsupervised method that eschews the need for OOD data. Our approach hinges on the computation of an inner product between the trajectory of a test sample and the average training trajectories, allowing us to gauge the similarity between the two. A low inner product signifies that the test sample is likely to be an OOD instance.  Through rigorous experimentation, we unveil the efficacy of our method, achieving competitive results and outperforming state-of-the-art techniques in the detection of OOD samples. In doing so, we not only advance the field but also illuminate a new horizon for future explorations in the intricate dance between deep networks and the diverse tapestry of data they encounter."}
{"paper_id": "416", "abstract": "In the realm of image processing, the quest for high-resolution (HR) imagery from their low-resolution (LR) counterparts has long been a challenge, particularly in the unpaired image super-resolution (SR) landscape. Here, we embark on a journey to unravel the intricacies of this problem through the lens of optimal transport (OT) theory, revealing a pivotal truth: the solutions to the unpaired SR objectives, when regularized with content losses, inherently align with the principles of OT. Yet, this revelation also uncovers a critical flaw—these solutions exhibit a systematic bias, transforming the distribution of LR images into one that diverges from the true HR distribution.  Driven by this insight, we delve deeper into the realm of unbiased OT maps, employing perceptual transport costs to rectify this bias. Our exploration leads us to a novel algorithm, grounded in the theory of integral probability metrics, which adeptly fits these unbiased OT maps. In doing so, we not only address the bias but also forge a path toward enhanced performance in the unpaired SR task.  The results of our algorithm speak volumes, showcasing a significant leap forward in the quality of image reconstruction, as measured by both perceptual metrics and the peak signal-to-noise ratio (PSNR). In this endeavor, we have not merely tackled a technical challenge; we have illuminated a new path in the landscape of image processing, one that promises greater clarity and precision in the transformation of images."}
{"paper_id": "417", "abstract": "In the realm of 3D scene perception, point cloud data stands as a beacon of clarity, illuminating the intricate tapestry of our environment. Yet, the quest for effective 3D scene representation often finds itself ensnared by the constraints of limited annotated data, particularly when it comes to new target domains. To navigate this treacherous terrain, we delve into the challenge of Domain Generalization (DG)—the art of crafting models that can adapt seamlessly to a multitude of unseen target domains, all while learning from a singular source dataset.  In our exploration, we unveil the Single-dataset Unified Generalization (SUG) framework, a robust construct designed to harmonize the inter-domain adaptation of a model trained on a solitary dataset. At the heart of SUG lies two innovative components: First, the Multi-grained Sub-domain Alignment (MSA) method, which deftly divides the source dataset into diverse sub-domains, compelling the model to engage with a rich tapestry of domain variations across multiple feature granularities. Second, the Sample-level Domain-aware Attention (SDA) strategy, which dynamically assesses the inter-domain distances of individual samples, ensuring that the adaptation process remains balanced and equitable for all.  Our rigorous experiments, conducted on benchmark datasets such as ModelNet-10, ShapeNet-10, and ScanNet-10, reveal the formidable efficacy of the SUG framework. The results not only substantiate our approach but also demonstrate its potential to elevate the DG capabilities of various baseline models, paving the way for a new era of adaptable and versatile 3D scene representations."}
{"paper_id": "418", "abstract": "In the ever-evolving realm of deep learning, the ability to detect shifts in data distribution stands as a pivotal challenge, one that has garnered significant attention in the academic sphere. In this paper, we unveil a novel approach to distribution shift detection, intricately woven with a theoretical underpinning that ensures the construction of classifiers capable of delivering guaranteed coverage. This innovative method not only enhances our detection capabilities but also serves as a robust foundation for our windowed detection algorithm. Through rigorous empirical analysis, we demonstrate that our approach outstrips existing methodologies, particularly in the realms of CIFAR-10 and ImageNet, when employing models such as ResNet-18, ResNet-50, and EfficientNet. Our findings illuminate a path forward in the quest for more resilient machine learning systems, capable of adapting to the dynamic landscapes of real-world data."}
{"paper_id": "419", "abstract": "In the realm of 3D scene generation, autoregressive transformers have emerged as powerful allies, crafting layouts with remarkable finesse. Yet, a shadow lingers over their capabilities: these models are constrained by a rigid sequential generation order, allowing for conditioning only on elements that precede a given point in the sequence. This limitation shackles their potential, restricting their ability to adapt to dynamic scene configurations and to condition on a diverse array of attributes—be it the type, position, or orientation of objects within the scene.  To break free from these chains, we introduce a groundbreaking architecture that enhances the capabilities of existing autoregressive transformers. Our approach is built on two innovative pillars: first, we train our model to maintain a remarkable invariance across object permutations, achieved through the use of a contrastive objective that randomly shuffles object tokens during training. Second, we incorporate a transformer encoder that empowers the model to engage in bidirectional cross-attention, enabling it to consider the entire conditioning sequence at every step.  This architecture not only allows for the seamless integration of object-level and attribute-level conditioning but also sets a new standard for performance in 3D scene generation. We put our method to the test across four distinct tasks: unconditional generation, object-level conditioning, attribute-level conditioning, and the detection of attribute-level outliers. In a head-to-head comparison with three leading autoregressive baselines, our approach shines, either matching or surpassing the state of the art in all evaluated metrics. With this advancement, we unlock new possibilities in the creation of 3D scenes, paving the way for a future where imagination and precision can coexist harmoniously."}
{"paper_id": "420", "abstract": "In the ever-evolving realm of machine learning, the quest for robustness in neural networks stands as a beacon of necessity, illuminating the path through the treacherous terrain of adversarial attacks and the unpredictable shadows of distribution shifts. In this exploration, we delve into the intricate art of transfer learning, where the wisdom gleaned from a well-trained model in one domain is wielded to bolster the defenses of a related task in a distinct domain. Our investigation unfolds across five pivotal questions: (1) Which training methodologies forge the most resilient source models? (2) Does the transfer of these robust source models preserve their fortitude? (3) How do targeted retraining strategies in the target domain influence robustness? (4) Which training and retraining approaches emerge as champions against distribution shifts? (5) Is there a discernible correlation between the transferability of models and their inherent robustness?  To illuminate these inquiries, we construct a transfer learning framework that separates a feature extractor, meticulously trained on the source domain, from a classifier that undergoes retraining within the target domain. Our findings reveal that the robustness of source models, honed through various training methodologies, does indeed transcend the boundaries of their origin, allowing for seamless adaptation to new tasks. While targeted retraining in the target domain does contribute to an enhancement in robustness, its impact pales in comparison to the formidable resilience bestowed by the source models themselves. Notably, our exploration uncovers a striking correlation between model robustness and transferability, as measured by the H-score—a metric that quantifies the efficacy of representations learned in the source domain for tackling target tasks. In this intricate dance of learning, we find that the strongest foundations lay not just in the models we build, but in the care we take to nurture their resilience from the outset."}
{"paper_id": "421", "abstract": "In the realm of artificial intelligence, deep reinforcement learning (DRL) has emerged as a powerful ally, mastering the art of navigating complex environments through the lens of reward. Yet, as we venture into the territory of safety-critical applications, a shadow looms—agents that, while adept at their tasks, often stray into territory that is not merely undesirable but perilous. To counter this, researchers have turned their attention to constrained DRL, a promising approach that seeks to anchor the training of DNNs in the constraints that define their ethical and operational boundaries.  In this paper, we unveil a groundbreaking method that empowers users to weave their domain expertise into the very fabric of the DRL training process. By harnessing the power of scenario-based programming, we transform the constraints that govern agent behavior into a rich tapestry of scenarios. Each scenario paints a vivid picture of desired or undesired behavior, allowing us to craft policies that not only respect these constraints but also thrive in the face of their challenges.  To illustrate the potency of our approach, we trained a policy for mapless navigation, a task that has proven both intriguing and treacherous in the past. Our results are nothing short of transformative, yielding policies that are not only safe but also remarkably efficient and predictable. To bolster our claims, we conducted a formal verification analysis, ensuring that our policies adhere to a suite of safety properties that are essential for real-world deployment. In doing so, we pave the way for a new era of intelligent agents that are not just capable, but also trustworthy and responsible."}
{"paper_id": "422", "abstract": "In the realm of Deep Reinforcement Learning (DRL), the quest for high performance often leads to a perilous trade-off with robustness. This duality has birthed a multitude of defense strategies, each with its own set of challenges. For instance, adversarial training demands a deep understanding of the attacker's tactics, while robust learning introduces noise into the training process, sometimes sacrificing efficiency in the process. Defensive distillation, a technique aimed at enhancing generalization, has proven to be less effective against a diverse array of attacks.  In this paper, we unveil a novel approach: Knowledge-based Policy Recycling (KPR). This innovative method harnesses the power of domain knowledge, specifically through the lens of auxiliary task policies and their interrelations, to fortify DRL agents against adversarial onslaughts. Our framework is inspired by recent advancements in supervised learning, where domain knowledge is wielded as a structural prior to bolster resilience against attacks.  KPR operates by weaving together the predictions of the primary task policy with those of its auxiliary counterparts, guided by established relationships and domain knowledge. We employ graph neural networks as the foundation for our approach, allowing for a natural integration of graph-based domain insights while maintaining the malleability necessary for learning from interaction data. The ensemble of policies is deftly fused into a new, robust task policy through a straightforward, parameter-free method.  Our empirical findings reveal that KPR significantly enhances performance across various attacks in both low- and high-dimensional environments, including the renowned Atari Games and the complex Robot Food Court Environment. In this way, we pave a new path toward more resilient reinforcement learning, one that marries the wisdom of domain knowledge with the power of adaptive learning."}
{"paper_id": "423", "abstract": "In the realm of large-scale pre-trained models, few have garnered as much acclaim as CLIP, a marvel of multimodal understanding. Yet, as with all powerful entities, it is not without its flaws. In our exploration, we unveil a perplexing phenomenon we term \"Cognitive Disorder\" (CD), which plagues the continual training of CLIP. This disorder arises from the intricate dance of representation vectors, which, as CLIP navigates the waters of continual learning, undergo a transformation that can only be described as disorienting.  We delve into this issue through a spatial geometry lens, tracing the paths of representation vectors as they twist and turn within the high-dimensional sphere of the CLIP model. Our analysis reveals two distinct spatial phenomena at play: first, the \"Intra-modal Rotation,\" where the representation space of individual modal encoders spins about its axis, accompanied by a subtle shift in topology; second, the \"Inter-modal Deviation,\" a disconnect that emerges between the modal encoders as they struggle to align their understanding of the same entities.  Armed with these insights, we introduce a novel framework, Mod-X, designed to combat CLIP's Cognitive Disorder. Mod-X operates by selectively harmonizing the off-diagonal information matrices between the current and past models during continual training. In doing so, it adeptly preserves the cognitive integrity of previously learned entities, allowing the model to adapt seamlessly to new data while maintaining a robust understanding of the old.  Our experiments, conducted on both large-scale and diverse datasets, demonstrate the efficacy of Mod-X in alleviating CLIP's cognitive struggles, paving the way for more resilient and adaptable models in the ever-evolving landscape of multimodal learning."}
{"paper_id": "424", "abstract": "In the realm of reinforcement learning, where the quest for mastery unfolds like a grand narrative, Model-Based Reinforcement Learning (MBRL) stands as a beacon of efficiency, wielding the power of predictive models to illuminate the path ahead. Yet, as we delve into the intricate tapestry of continual learning, where the threads of experience weave together in complex patterns, MBRL encounters challenges that threaten to unravel its potential. The ever-expanding tapestry of repetitive experiences can overwhelm the model, leading it down the perilous path of overfitting—trapped in a cycle of familiarity that stifles growth.  In this work, we embark on a journey to reshape the paradigm of experience replay within the MBRL framework, forging a new path for continual learning. We propose a novel approach that empowers the model to discern the predictable from the unpredictable, judiciously discarding the former to make way for the latter. By doing so, we not only trim the excess of redundant experiences but also cultivate a dynamic replay buffer that brims with the rich diversity of useful information.  Our findings reveal a remarkable transformation: the model, freed from the shackles of repetitive experiences, achieves a level of performance previously unattainable. The wall-time required for training shrinks dramatically, and the model exhibits a newfound resilience against the treacherous waters of catastrophic forgetting. In this unfolding narrative, we witness the potential of MBRL not just as a tool, but as a transformative force in the landscape of continual learning."}
{"paper_id": "425", "abstract": "In the realm of machine learning, where the shadows of overfitting and underfitting loom large, Neural Networks (NNs) have emerged as powerful allies, wielding the ability to tackle an array of intricate challenges. Yet, amidst their triumphs, a persistent question lingers: How can we harness the potential of NNs to forge solutions that are not only accurate but also steeped in interpretability? In this exploration, we embark on a journey to weave together the intricate tapestry of sparse Neural Networks with the elegant threads of logic programming, creating a new path forward.  We introduce the Neural Logic Programming Network (NLPN), a groundbreaking architecture that melds the strengths of both domains, designed to tackle the formidable task of relational reasoning. At its core, the NLPN employs a neural function to deftly select a compact subset of rules from a vast library, each one crafted to capture the essence of a specific relationship within the data. This innovative approach not only enhances efficiency but also allows the network to focus on the most relevant aspects of the problem at hand.  But we do not stop there. To further illuminate the inner workings of our creation, we unveil the Neural Logic Programming Graph (NLPG). This graphical representation serves as a beacon, translating the abstract concepts of the NLPN into tangible, human-understandable terms. Through the NLPG, we can trace the flow of information and the application of rules, revealing the reasoning behind the network's decisions.  Our experiments, conducted on the esteemed Amazon multi-domain datasets, stand as testament to the prowess of the NLPN. The results, both qualitative and quantitative, illuminate the path forward, showcasing a future where the depth of logic and the agility of neural networks unite to solve complex problems with clarity and precision."}
{"paper_id": "426", "abstract": "In the realm of reinforcement learning, a powerful tool emerges in the form of imitation learning, enabling agents to master tasks through the study of expert demonstrations—think of a skilled pilot navigating the skies or a deft robot maneuvering through its environment. Yet, as with any formidable technique, challenges loom. Traditional approaches often falter, relying on discriminators that can be easily misled by trivial discrepancies between expert actions and those generated by the agent. This oversight leads to sparse reward signals, which can stifle the learning process and hinder the agent's development.  Enter our innovative solution: the Auto-Encoding Adversarial Imitation Learning (AEAIL) framework. By conceptualizing the reward function as an auto-encoder, we redefine the paradigm. Our method zeroes in on the comprehensive differences between expert and agent-generated samples, forging a robust and efficient imitation learning strategy. The results speak for themselves—our AEAIL outshines the competition, delivering superior performance across a diverse array of tasks and environments.  Through rigorous experimentation, we unveil the versatility of our approach, demonstrating its efficacy across a spectrum of auto-encoders and distribution divergences. In doing so, we not only advance the field of imitation learning but also pave the way for future innovations that will reshape our understanding of agent learning."}
{"paper_id": "427", "abstract": "In the realm of visual storytelling, the art of photorealistic video style transfer emerges as a powerful tool, enabling the transformation of images into cinematic narratives with remarkable finesse. Yet, this endeavor is fraught with challenges. Traditional methods often falter, producing stylized outputs marred by spatial distortions and flickering artifacts that undermine the very essence of photorealism.   In this paper, we unveil ColoristaNet, a groundbreaking framework designed to navigate these treacherous waters. Our approach is rooted in the premise that by deftly removing the inherent style of an image while preserving its structural integrity, we can then restore it to its original form, aligning it with a desired reference style. To achieve this, we introduce a self-supervised learning paradigm that eschews the Gram loss, typically employed for style matching, during the training phase.  At the heart of ColoristaNet lies DecoupleIN, a novel feature transformation module that skillfully disentangles the process of style removal and restoration. This innovative design allows us to match the statistics of content features with those of style references without succumbing to the pitfalls of unrealistic stylization. Moreover, to uphold the temporal consistency essential for video stylization, we leverage optical flow estimation and ConvLSTM units to propagate style information seamlessly across consecutive frames.  Our extensive qualitative results and a user study compellingly demonstrate that ColoristaNet not only meets but exceeds the expectations set by the state-of-the-art, achieving a harmonious balance between artistic expression and photorealism."}
{"paper_id": "428", "abstract": "In the ever-evolving landscape of machine learning, the art of positional encoding has emerged as a pivotal element in the architecture of transformers. These remarkable models have made significant strides across realms of natural language processing, vision, and audio. At the heart of their prowess lies the intricate assignment of unique representations to each position within a sequence, enabling transformers to discern the context of input tokens with precision. Among the many encoding strategies available, relative positional encoding stands out for its ability to enhance performance while liberating models from the constraints of input length.  Yet, as the spotlight has shifted towards linear transformers, which boast a remarkable linear space-time complexity, a gap has become apparent. Most existing linear transformers continue to rely on absolute positional encoding, a limitation that stems from the design of relative methods tailored for traditional transformers, often proving incompatible with their linear counterparts. This conundrum has largely remained uncharted territory in the realm of research.  In this work, we embark on a quest to bridge this divide, forging a principled framework that allows us to derive relative positional encoding suitable for both linear and conventional transformers. Our exploration reveals that the diversity of existing encoding methods can be distilled down to a selection of fundamental query, key, and relative positional matrix primitives. By deftly choosing and combining these primitives, we unveil a versatile family of relative positional encoding methods, which we have dubbed linearized relative positional encoding (LRPE). This innovative approach not only preserves the coveted linear space-time complexity in linear transformers but also extends its applicability to traditional transformers.  Through rigorous experimentation across autoregressive and bidirectional language modeling, as well as a variety of downstream tasks including machine translation and text classification, we demonstrate the formidable efficacy of the LRPE family. Our findings underscore its competitive prowess in capturing relative positional information, often outshining previous methodologies. In this way, we not only advance the state of the art in transformer-based models but also illuminate a path forward for future explorations in the intricate dance of positional encoding."}
{"paper_id": "429", "abstract": "In the realm of multi-agent reinforcement learning (MARL), the quest for rewards often feels like a hero's journey—a path fraught with challenges and filled with the need for balance. Agents must navigate the delicate dance of exploration and exploitation, each step crucial for their collective success. Yet, as the number of agents grows, the complexity of their interactions multiplies exponentially, creating a labyrinth of decision-making.  In this paper, we unveil a novel framework designed to tackle the multi-agent exploration-exploitation trade-off head-on. Our approach introduces a dynamic allocation of target entropies, tailored not only to the individual agents but also to the ever-flowing passage of time. At the heart of our strategy lies a groundbreaking metric, derived from the partial derivative of the joint value function of pure return with respect to policy action entropy. This clever construction allows us to gauge the extent to which each agent's exploration contributes to their returns, guiding our adjustments with precision.  By imposing a constraint on the total target entropy across all agents, we ensure that our framework not only enhances exploration but also respects the unique needs of each participant in the multi-agent saga. Our experimental results speak volumes, showcasing the effectiveness of our approach in orchestrating this intricate balance. In a world where cooperation is key, our framework emerges as a beacon of clarity in the chaos of multi-agent learning."}
{"paper_id": "430", "abstract": "In the realm of reinforcement learning, the quest for mastering the intricate dance of Markov decision processes (MDPs) often leads to a perilous journey, fraught with the specter of high sample complexity and the looming threat of suboptimal policies. When the dynamic landscape itself becomes a fickle creature, swaying within the bounds of an uncertainty set, the challenges only multiply. Yet, in this paper, we unveil a beacon of hope: the first provably efficient policy optimization algorithm tailored for robust MDPs, navigating the treacherous waters of a rectangular uncertainty set.  Our approach is a testament to ingenuity, employing a dual-conjugate bonus function that deftly encapsulates the dual uncertainty inherent in the robust Bellman equation. This clever construction allows us to weave together the threads of optimism and robustness, guiding our algorithm toward a path of exploration that is both strategic and necessary.  In the episodic framework of robust MDPs, we proudly proclaim our achievement: our algorithm operates with a near-minimal memory footprint, requiring only a single pass through the data, yet it still delivers a regret bound that scales as O(√K), where K represents the number of episodes. To our knowledge, this marks the first regret guarantee ever bestowed upon the online robust MDP challenge.  But we do not stop there. When the shadows of uncertainty are cast aside, and the nominal transition model reigns supreme, our results beautifully harmonize with the existing landscape of non-robust policy optimization. For those eager to delve deeper into our findings, our code awaits in the open arms of the supplementary materials."}
{"paper_id": "431", "abstract": "In the realm of deep learning, where the quest for efficiency and accuracy is ever-consuming, adaptive gradient methods have emerged as powerful allies. Yet, despite their potential, they often find themselves shackled by poor generalization performance, a lamentable truth that has left many researchers scratching their heads. Enter the Dimension-Reduced Adaptive Gradient (DRAG) method, a bold new approach that seeks to transcend these limitations.  At its core, DRAG reimagines the optimization landscape by deftly navigating the balance between the expansive parameter space of adaptive gradient methods and the focused trajectory of SGD along a singular gradient direction. By employing a trust-region-like optimization strategy, DRAG elegantly addresses the quest for the optimal update, transforming the multidimensional gradient into a tapestry of \\(n\\) independent directions, each imbued with its own learning rate. This innovative approach not only streamlines the optimization process but also significantly curtails the adaptivity that has long plagued adaptive methods.  Our theoretical underpinnings reveal that DRAG possesses the remarkable ability to converge, boasting a stochastic gradient complexity of \\(O(\\epsilon^{-4})\\) for finding an \\(\\epsilon\\)-approximate first-order stationary point in non-convex settings. This performance aligns seamlessly with the established lower bound, showcasing the robustness of our method.  In practical terms, DRAG shines, delivering faster convergence and superior generalization across a variety of benchmark tasks. In this new era of deep learning, DRAG stands as a beacon of hope, illuminating the path toward more effective optimization strategies."}
{"paper_id": "432", "abstract": "In the realm of industrial systems, anomalies often lurk in the shadows, heralding impending failures that can strike at any moment. These unpredictable events, by their very nature, are rare, making them formidable foes for machine learning models tasked with their detection. Traditional classification methods, when faced with the stark imbalance of anomalies against the norm, struggle to rise to the occasion.   Enter the realm of deep learning, where the LSTM shines as a beacon of hope. By modeling the intricate dance of time-series data, LSTMs capture the essence of temporal dependencies, allowing them to sift through the noise and illuminate the anomalies hidden within. In this paper, we unveil a novel approach: the quantile LSTM (q-LSTM). This innovative architecture learns to estimate the 50th, 75th, and 95th percentiles of a device's operational behavior, crafting a robust forecast that serves as a foundation for anomaly detection.  But we do not stop there. We introduce a suite of quantile-based LSTM methodologies, including the iqr-LSTM and median-LSTM, each offering unique advantages in the quest for accuracy. At the heart of our approach lies the Parameterized Elliot Function (PEF), a versatile activation function that enhances our LSTM's capabilities. The PEF, with its learnable parameters, provides a more flexible and adaptive framework than its non-parameterized counterparts, such as the traditional sigmoid and tanh functions.  Our experiments, conducted across a diverse array of industrial and non-industrial datasets, including the prestigious Numenta Anomaly Benchmark, reveal the formidable prowess of our proposed techniques. The results speak volumes, showcasing the superior performance of our LSTM-based anomaly detectors, which outshine both deep learning and non-deep learning alternatives alike. In this battle against the unknown, we have crafted a powerful tool for the detection of anomalies, ensuring that the shadows of failure are cast aside."}
{"paper_id": "433", "abstract": "In the realm of graph contrastive learning (GCL), the quest for high-quality augmented samples stands as a pivotal challenge. Recent explorations have ventured into the intricate territory of rationale discovery, unveiling promising strategies for crafting these augmented views. Yet, a critical gap remains: most existing methods focus solely on node-wise or edge-wise rationales, neglecting the rich interplay between nodes and edges. This oversight often leads to a fragmented understanding of the graph's structure, as the interconnections are either overshadowed or entirely disregarded.  To address this limitation, we introduce a groundbreaking approach known as \"self-attentive rationalization,\" a transformative method that harmonizes the dual functions of rationale discovery and encoding through the power of self-attention. This innovative technique not only generates both node- and edge-wise rationales with remarkable synergy but also enhances the generalization capabilities of the pre-trained model across a diverse array of downstream tasks.  By weaving together the insights gleaned from both node- and edge-wise transformations, our method empowers the model to discern the unique contributions of each element within the graph, fostering a more holistic understanding. The results speak for themselves: our self-attentive rationalization approach sets a new benchmark in the field of graph pre-training, significantly advancing the state of the art and paving the way for future innovations in graph representation learning."}
{"paper_id": "434", "abstract": "In the realm of decoding brain activity, where the quest for understanding the intricate dance of neural signals unfolds, we embark on a journey to enhance the traditional subject-level (SL) decoding methodologies. Our exploration delves into the captivating world of magnetoencephalography (MEG) data, specifically from a visual task, allowing us to decode the hidden categories of visual stimuli presented to a group of subjects. While the SL approach has served us well, yielding impressive classification accuracies, it is limited by its subject-specific nature, failing to harness the collective wisdom of the group.  To bridge this gap, we introduce a groundbreaking architecture for group-level (GL) decoding that not only acknowledges the unique characteristics of each subject but also empowers the model to generalize across them. At the heart of our approach lies the innovative use of subject embeddings, which serve as a bridge, enabling the GL model to adapt its predictions based on the individual nuances of each subject.  Through rigorous experimentation, we unveil the compelling advantages of our GL model over its SL counterpart. We demonstrate that our method significantly outperforms naive group modeling, achieving an impressive 2.5% increase in classification accuracy on average across all categories. Moreover, our GL model shines in its ability to generalize to new subjects, boasting a 1.3% improvement over SL models when faced with unseen subjects.  But the story does not end there. We delve into the depths of our GL model, exploring how it captures the rich spatio-temporal and spectral information embedded within the MEG data. Our findings reveal that the model adeptly learns to associate specific spatio-temporal patterns with distinct spectral features, illuminating the pathways through which information flows within the brain.  Finally, we harness the power of our GL model to extract meaningful insights, uncovering that the learned features align closely with established neuroscientific theories. This not only validates our approach but also opens the door to new avenues of research, where the fusion of advanced decoding techniques and deep learning can illuminate the mysteries of brain function."}
{"paper_id": "435", "abstract": "In the realm of machine learning, where the shadows of overfitting and the specter of underfitting loom large, the quest for a model that can generalize with grace is akin to a hero seeking the elixir of power. In this paper, we unveil a novel approach to active learning, one that boldly confronts these challenges head-on. We introduce Sharpness-Aware Active Learning (SAAL), a method that deftly navigates the loss landscape, selecting instances with a keen eye for high loss sharpness. This focus not only enhances our ability to generalize but also imbues our models with a newfound resilience.  At the heart of SAAL lies a simple yet profound concept: by maximizing the maximally perturbed loss, we can unearth instances that, when labeled, will lead our model down a path of improved generalization. Our theoretical exploration reveals that the acquisition score we employ is intricately tied to the generalization prowess of the model itself. Through rigorous experimentation, we demonstrate that SAAL stands shoulder to shoulder with the best active learning methods, all while requiring fewer labeled instances to achieve its lofty goals. In this journey, we find not just a tool, but a beacon of hope for the future of machine learning."}
{"paper_id": "436", "abstract": "In the realm of distance metric learning (DML), the quest for an embedding function that brings semantically akin samples closer together while placing disparate ones at a distance in the Euclidean plane is a noble one. Yet, the prevailing wisdom in this field often hinges on a straightforward architecture: a convolutional neural network followed by a global pooling layer, with the most common choice being global average pooling (GAP). This method, while widely adopted, has sparked much debate. Some have likened it to a tapestry of numerous semantic entities, each pixel woven into the fabric of the feature map, yet the implications of this for the resulting representation space remain murky.  In this paper, we embark on a journey to reexamine the role of GAP within the DML landscape. We propose a novel, learnable, and generalized version of GAP that empowers the model to learn which subset of semantic entities to harness and the weights to bestow upon them during the averaging process. To bring this generalized GAP to life, we reframe it as the solution to an optimization problem, allowing for the possibility of a 0-weight that effectively discards certain features. We rigorously demonstrate that the original GAP emerges as a specific instance of this optimization problem under a particular parameterization.  Drawing inspiration from the rich literature on optimal transport-based top-k operators, we introduce an efficient algorithm for computing gradients within our proposed framework. This innovation enables the learning of the optimal subset and weights. To further refine our approach, we incorporate a regularization term that promotes discriminative features, effectively mitigating the influence of background classes—those pesky nuisance variables that can cloud our understanding.  Our theoretical insights are put to the test through a series of synthetic empirical studies, revealing that our pooling method not only selects more advantageous subsets but also enhances generalization capabilities. To substantiate our claims, we present a rigorous proof of concept. Finally, we showcase the versatility of our method, which can be seamlessly integrated with any DML loss function, as the global pooling operation serves as a universal component across them. In doing so, we unlock new possibilities for advancement in the field of distance metric learning."}
{"paper_id": "437", "abstract": "In the ever-evolving realm of neural networks, the concept of the lottery ticket hypothesis (LTH) emerged as a beacon of hope for those seeking to trim the excess from dense architectures. This hypothesis posits that within every dense neural network, there lies a sparse sub-network that, when trained in isolation, can achieve performance on par with its more expansive counterpart. Recent explorations have unveiled a multitude of initialization strategies that enhance the likelihood of uncovering these sparse gems.   In our study, we delve into a novel approach to weight initialization, one that imbues each neuron with an adaptive learning rate, allowing it to navigate the training landscape with greater finesse. This innovation not only bolsters the chances of discovering high-quality lottery tickets but also reveals a fascinating truth: under the right conditions, it becomes possible to generate multiple tickets from a single network, each boasting comparable performance yet exhibiting strikingly different structures.  As we scrutinize these diverse lottery tickets, we uncover a subset of connections that remain resolutely stable across the spectrum of initializations. These resilient links, it seems, hold the key to understanding the emergence of lottery tickets and could pave the way for more efficient identification of high-quality sub-networks in the future. In this intricate dance of initialization and discovery, we find not just potential, but the very essence of what makes neural networks both powerful and endlessly intriguing."}
{"paper_id": "438", "abstract": "In the realm of image segmentation, where the quest for clarity often feels like an arduous journey through a labyrinth, we unveil a groundbreaking approach that harnesses the power of reinforcement learning (RL). Our method reimagines the instance segmentation challenge as a grand adventure in graph agglomeration, where the agent learns to predict the elusive weights of an image's superpixel adjacency graph. From these predictions, the magic of non-differentiable graph partitioning reveals the hidden identities of segmented objects.  But we do not stop there. We weave together a tapestry of high-level priors, drawing from the rich tapestry of object and image-level rules that guide our way. These rules, while not differentiable, are vital for steering the RL agent toward optimal actions. To bridge this critical gap, we introduce a novel strategy for spatially decomposing rewards into localized subgraphs, allowing us to approximate the non-differentiable reward function with precision.  Our experiments span a diverse array of scenarios, from the meticulously ordered grids of synthetic images to the intricate complexities of real-world objects and biological specimens. The results are nothing short of remarkable, showcasing our method's ability to deliver state-of-the-art segmentations without the need for costly instance-level annotations. In this new paradigm, we unlock the potential of high-level priors, paving the way for a future where segmentation is not just an endeavor, but a triumph of ingenuity and learning."}
{"paper_id": "439", "abstract": "In the realm of decentralized training, where the specter of Byzantine attacks looms large, we embark on a quest to fortify our defenses against these insidious threats. Picture a world where a select few nodes, corrupted by malicious intent, seek to undermine the integrity of our training process. These attackers, cloaked in anonymity, possess the ability to manipulate their gradients, all while maintaining a facade of legitimacy. They are not merely outliers; they are strategic saboteurs, capable of wreaking havoc on our convergence.  To counter this formidable challenge, we introduce CLIPPEDGOSSIP, a robust training algorithm crafted specifically for the constraints of a communication-constrained graph. Our approach hinges on a clever clipping mechanism, designed to deftly mitigate the undue influence wielded by these adversarial nodes. By limiting the impact of their gradients, we ensure that our training remains steadfastly focused on the path toward a global solution.  Through a blend of rigorous theoretical analysis and compelling empirical evidence, we unveil the prowess of CLIPPEDGOSSIP. Our findings reveal that it not only withstands the onslaught of Byzantine attacks but does so with remarkable efficiency, achieving faster convergence rates than its predecessors in the face of such adversities. In this battle against chaos, we have crafted a tool that stands tall, guiding us toward a future where robustness and resilience reign supreme."}
{"paper_id": "440", "abstract": "In the realm of graph analysis, the quest for shortest-path (SP) distance representations has emerged as a pivotal challenge, particularly in the vast and intricate landscapes of large-scale graphs. Current methodologies, whether rooted in learning or theory, often falter, either sacrificing precision for speed or offering only opaque representations that lack clarity.   In this paper, we unveil a groundbreaking approach: the Betweenness Centrality-based Distance Resampling (BCDR). This innovative method not only enhances the accuracy of SP distance approximations but also does so with remarkable efficiency and interpretability. At the heart of BCDR lies a dual strategy. First, we employ a betweenness centrality (BC)-guided random walk, which deftly navigates the graph, uncovering a broader spectrum of SP distance correlations within the constraints of a limited number of steps. Second, we introduce a technique of distance resampling, meticulously designed to safeguard the integrity of SP distance relations. This is achieved by implicitly dismantling an SP distance-based similarity matrix, ensuring that our learned representations remain faithful to the original graph’s structure.  Our rigorous evaluation spans a diverse array of real-world and synthetic graphs, revealing that BCDR significantly outperforms its predecessors, boasting an average accuracy improvement of 25% and a notable increase in query speed—approximately 25-30%—over existing methods. In this way, we not only push the boundaries of what is possible in graph analysis but also illuminate the path forward for future research in the field."}
{"paper_id": "441", "abstract": "In the realm of neural network training, the allure of second-order methods, such as the illustrious Newton's method and the elegant natural gradient descent, has long captivated researchers. These techniques promise to accelerate convergence, yet they are burdened by two significant challenges. First, the computational demands of inverting the Hessian matrix for expansive networks prove to be a formidable task. Second, networks trained under the auspices of second-order information often exhibit a troubling lack of generalization.   In this paper, we unveil a groundbreaking approach that intertwines the principles of second-order optimization with the familiar framework of first-order methods. By deftly splitting the iterative optimization problem into a two-stage scheme, we introduce a novel concept: Newton losses. These Newton losses serve as a bridge, seamlessly integrating second-order insights into the training of neural networks.   Our exploration delves into the application of Newton losses across a diverse array of algorithmic losses, scrutinizing their performance on two widely recognized benchmarks—sorting and shortest-path problems. The results are compelling: Newton losses not only enhance performance in the face of particularly challenging loss functions but also maintain steadfast consistency when the going is easier.   For those eager to delve deeper into our findings, our code and trained models await you at https://github.com/stephanwolff/newton_losses."}
{"paper_id": "442", "abstract": "In the realm of machine learning, where the intricacies of deep neural networks often shroud their decision-making processes in an impenetrable fog, the quest for understanding becomes paramount, especially in critical applications like healthcare and finance. In this paper, we unveil SeqSHAP, a groundbreaking Shapley value-based method designed to illuminate the shadows cast by deep neural networks that grapple with sequential data.  At the heart of SeqSHAP lies a novel approach to segmentation, which meticulously divides sequences into coherent subsequences, each rich with semantic meaning. This segmentation not only enhances interpretability but also breathes new life into the explanation of model predictions. By employing Shapley values, we assign attribution scores to feature units within these subsequences, effectively capturing the essence of their contributions to the final outcome.  Our method is rigorously tested within the dynamic landscape of online transaction fraud detection, drawing upon two expansive real-world datasets teeming with sequential features. Through a thorough analysis of the local explanations generated by SeqSHAP, we demonstrate its remarkable ability to provide clear, intuitive insights that resonate with human understanding. In doing so, we bridge the gap between complex models and the need for transparency, paving the way for a more trustworthy future in machine learning."}
{"paper_id": "443", "abstract": "In the realm of natural language processing, the art of Chinese word segmentation (CWS) stands as a pivotal first step, essential for unlocking the potential of downstream tasks. Yet, despite the remarkable advancements in pre-training models, the quest for accurate word segmentation remains fraught with challenges. One of the most pressing issues is the segmentation of Out-of-Vocabulary (OOV) words, which often eludes even the most sophisticated models.   In this paper, we unveil a novel approach: the Boundary-Enhanced Decoder (BED). Inspired by the innate abilities of human cognition, BED operates on the principle that humans adeptly identify word boundaries, tackling segmentation challenges with a strategic two-step process. First, we pinpoint the easily segmentable positions within a sentence, dividing it into manageable segments. Then, we apply our segmentation prowess to each part with greater precision.  Our extensive experiments, conducted on three prominent datasets, reveal that the BED decoder significantly enhances the performance of the baseline model, particularly in the segmentation of OOV words. The results speak volumes, showcasing a marked improvement of 1.15%, 0.94%, and 0.82% in F1 scores on the SIGHAN2005, SIGHAN2009, and MSRA datasets, respectively. In this way, we not only address a critical gap in the field but also pave the way for more accurate and robust word segmentation in Chinese text."}
{"paper_id": "444", "abstract": "In the realm of generative modeling, Denoising Diffusion Probabilistic Models (DDPMs) have emerged as a formidable force, wielding the power to create high-quality samples across a multitude of domains. Yet, as we delve into the intricacies of real-world applications, we encounter challenges that threaten to undermine their prowess. Enter Tabular Diffusion Models (TabDMs), a specialized subclass of DDPMs crafted specifically for the complexities of tabular data.   In our exploration, we unveil TabDDPM, a groundbreaking design that stands as a beacon of simplicity and versatility within the TabDM landscape. This model is not bound by the constraints of data type; it elegantly accommodates both numerical and categorical features, making it a true champion for the diverse datasets that populate our world.   Our findings reveal that TabDDPM not only competes but often surpasses the leading methods in the tabular data landscape, achieving state-of-the-art performance across a spectrum of benchmarks. The advantages are twofold: first, the robustness of the diffusion model itself, which adeptly navigates the complexities of tabular data; second, the innovative preprocessing techniques we’ve implemented, which enhance the training process and elevate the quality of the generated data.  In a world where privacy concerns loom large, the ability to generate synthetic data becomes paramount. TabDDPM stands ready to address this need, offering a solution that not only preserves privacy but also enriches the quality of data available for training. For those eager to explore this frontier, our source code awaits at https://github.com/automl/TabDDPM."}
{"paper_id": "445", "abstract": "In the realm of generative flow networks, or GFlowNets, a new dawn is breaking with the introduction of subtrajectory balance (SubTB) as a groundbreaking learning objective. This innovative approach empowers GFlowNets to learn from experiences that are fragmented into subtrajectories of any length, marking a significant advancement in the field.   Theoretically, SubTB emerges from the intricate dance of detailed balance (DB) and trajectory balance (TB) objectives, weaving a tapestry of improved credit assignment that enhances the learning process. Our empirical investigations across a diverse array of synthetic and real-world domains reveal a remarkable suite of benefits: (1) Models trained with SubTB converge with unprecedented speed, requiring fewer training iterations and exhibiting a remarkable resilience to the whims of hyperparameter choices. (2) In environments where previous methods faltered, often due to the elusive nature of rewards or the length of action sequences, SubTB shines, propelling performance to new heights. (3) The superior convergence properties of SubTB can be traced back to a reduction in the variance of the stochastic gradient, offering a compelling narrative that aligns with our theoretical predictions.  In this exploration, we not only push the boundaries of what GFlowNets can achieve but also illuminate the path forward for future research in generative modeling. The potential of SubTB is vast, and we are excited to see where this new horizon will lead us."}
{"paper_id": "446", "abstract": "In the realm of machine learning, where the shadows of distribution shifts loom large, we embark on a quest to recalibrate the venerable conformal prediction method. Our journey begins with a stark revelation: the beloved softmax classifier, when enveloped in the embrace of conformal prediction, often finds its confidence intervals straying from the sanctum of validity, particularly when faced with the capricious nature of new distributions.   To counter this challenge, we unveil a novel approach that requires but a single, albeit crucial, assumption: the existence of unlabeled examples from the target domain. With this tool in hand, we deftly recalibrate the coverage probability of our conformal predictor, steering it back toward the promised land of validity.   Our empirical explorations, conducted within the vibrant landscape of ImageNet and its intriguing variants, illuminate the path forward. The results are compelling: our recalibration technique not only restores the integrity of coverage probability but also diminishes the chasm between the expected and actual coverage, all while maintaining the efficiency of our predictions. In this way, we forge a way through the complexities of distribution shifts, ensuring that our methods remain steadfast and reliable."}
{"paper_id": "447", "abstract": "In the realm of graph-structured data, where connections weave a tapestry of relationships, the challenge of analyzing distributed subgraphs emerges as a pivotal concern. Enter federated graph learning (FGL), a promising approach that seeks to harness the collective power of subgraphs while safeguarding privacy. Yet, a critical oversight in this field is the assumption that these subgraphs are non-homogeneous—akin to disparate communities within a larger whole. However, we posit that the reality is far more complex: subgraphs often exhibit a rich tapestry of both homogeneity and heterogeneity, much like a city where both vibrant neighborhoods and stark contrasts coexist.  To navigate this intricate landscape, we introduce a novel framework, AdaFGL, designed to adaptively address the challenges posed by structure non-homogeneity. At its core, AdaFGL employs non-parametric label propagation to discern the underlying subgraph structure, intelligently selecting an optimal base model. In this way, it enhances the federated global knowledge extractor, refines the base predictor, and implements adaptive propagation mechanisms tailored to the local subgraphs.  Our extensive experiments reveal that AdaFGL not only meets but exceeds the performance benchmarks set by existing methods, particularly in scenarios characterized by structure non-homogeneity. In doing so, it paves the way for a more nuanced understanding of federated graph learning, one that embraces the complexities of real-world data."}
{"paper_id": "448", "abstract": "In the realm of neural networks (NN), the quest for understanding often feels like a hero's journey—a path fraught with complexity and intrigue. While the allure of high accuracy can be seductive, it frequently comes at the expense of clarity, leaving many to yearn for the simpler, more transparent models of yore. Enter the realm of global explanations, where we seek to illuminate the inner workings of NNs through the lens of surrogate models that are not only understandable but also rich in meaning.  In this paper, we unveil a groundbreaking approach: the creation of conceptual views that serve as an intermediary, a bridge between the intricate architecture of NNs and the more accessible realms of decision trees and formal concept lattices. These views are not merely abstract constructs; they are a vibrant tapestry woven from the very fabric of the data itself, allowing us to represent NNs in a way that resonates with human intuition.  With our conceptual views in place, we embark on a journey of comparison, employing the elegant framework of Gromov-Wasserstein distance to measure the dissimilarity between NN models. But our adventure does not end there. We delve deeper, extracting global insights in the form of human-comprehensible propositional statements, enhanced by the wisdom of background knowledge. In doing so, we forge a path toward a future where understanding and accuracy can coexist, creating a harmonious balance that benefits us all."}
{"paper_id": "449", "abstract": "In the realm of machine learning, the quest for generalization often leads us to the intricate landscape of bilevel optimization. This powerful technique, wielded through methods like stochastic gradient descent (SGD), has found its place in the heart of meta-learning and hyper-parameter optimization. Yet, the shadows of theoretical understanding and practical application have long loomed large over this domain.   In this paper, we embark on a journey to illuminate the generalization landscape of bilevel optimization, employing the lens of algorithmic stability. Our exploration traverses the intricate interplay of various settings, including strongly convex-strongly convex (SC-SC), convex-convex (C-C), nonconvex-nonconvex (NC-NC), and a particularly practical variant, nonconvex-strongly convex (NC-SC).   We unveil a novel connection, a bridge of equivalence, linking generalization error to both argument and uniform stability across a spectrum of randomized bilevel optimization algorithms. Our findings reveal that the generalization bounds for two-timescale (double-loop) methods, while theoretically intriguing, do not hold the same advantages as their single-timescale counterparts.   But we do not stop there. We extend our analysis to the uncharted territory of bilevel optimization where both the outer and inner level parameters are允许 to evolve through iterative updates—albeit within the constraints of Lipschitz continuous gradients. Here, we derive generalization bounds that further enrich our understanding.  To ground our theoretical insights, we present a series of empirical results, delving into applications such as meta-learning and hyper-parameter optimization. In doing so, we not only validate our theoretical constructs but also pave the way for future explorations in this vibrant field."}
{"paper_id": "450", "abstract": "In the ever-evolving realm of artificial intelligence, the Transformer architecture has risen to prominence, wielding remarkable prowess across a multitude of tasks. Yet, lurking in the shadows is a formidable challenge: its quadratic complexity, which hampers its ability to scale effectively with longer sequences. In response to this pressing issue, a multitude of efficient attention mechanisms have emerged, each claiming to enhance performance while maintaining computational efficiency. However, the prevailing benchmarks, such as the Long Range Arena, often focus on self-attention within synthetic tasks, neglecting the intricate realms of cross-attention and causal attention that demand equal scrutiny.  To address these shortcomings, we introduce the Comprehensive Attention Benchmark (CAB), a robust framework designed to evaluate the modeling capabilities of various attention mechanisms in real-world applications. CAB is built upon a meticulous taxonomy of attentive functionalities, categorized into four distinct patterns: non-causal self-attention, causal self-attention, non-causal cross-attention, and causal cross-attention. This taxonomy serves as a guiding principle for a pattern-wise comparison of attention mechanisms, allowing us to assess their respective strengths.  Through rigorous experimentation across a diverse array of tasks—spanning computer vision, natural language processing, speech processing, and time series forecasting—we unveil several critical insights. Firstly, we demonstrate that many purportedly efficient attention methods, while seemingly competitive, often fall short in the demanding arena of causal cross-attention, revealing a stark limitation in their modeling prowess when transitioning to different attention patterns. Secondly, we introduce the concept of efficiency length—a quantitative measure that illuminates the inherent inefficiency of existing methods when应对 relatively shorter sequences. Lastly, we explore the interpolation and extrapolation capabilities of long-context language models, uncovering promising avenues for the scalability of efficient attention mechanisms in this domain.  We envision that the CAB, alongside our comprehensive experimental efforts, will illuminate the fundamental challenges associated with efficient attention and inspire the creation of more sophisticated attention mechanisms. For those eager to delve deeper, our benchmark and related codes are readily accessible at https://github.com/Anonymous."}
{"paper_id": "451", "abstract": "In the realm of Reinforcement Learning (RL), the quest for mastering complex action spaces often feels like navigating a labyrinthine landscape, fraught with challenges that can overwhelm even the most seasoned practitioners. The sheer breadth of these action spaces, their continuous nature, or the intricate hybrid structures that defy simple categorization, pose formidable obstacles. Many existing approaches falter under the weight of these complexities, either requiring extensive domain expertise to navigate the myriad of action dimensions or succumbing to the inefficiencies that arise from their sheer size.  Enter the realm of Neural Discrete Reinforcement Learning (NDRL), a groundbreaking framework that seeks to transcend these limitations. At its core, NDRL embraces the power of learning a compact, discrete representation of action spaces—be they continuous or hybrid—empowering RL agents to operate with both efficiency and adaptability. At the heart of this innovation lies the Action Discretization Variational Auto-Encoder (AD-VAE), a sophisticated model that adeptly captures the nuanced relationships between action dimensions and their boundary values, all while preserving the essential semantics of the original action space.  But NDRL does not stop there. It introduces a dynamic ensemble Q-learning mechanism, designed to counteract the potential semantic shifts that can occur in the latent action space, ensuring that the decision-making process remains robust and reliable. To further enhance its capabilities, NDRL incorporates action remapping techniques, allowing it to seamlessly adapt to a diverse array of action spaces across various environments.  Our experiments reveal that the ADQ algorithm, a instantiation of our NDRL framework utilizing DQN, excels in achieving both sample efficiency and superior performance in a multitude of complex action spaces. In a world where complexity often reigns, NDRL stands as a beacon of innovation, guiding us toward a future where the intricacies of action spaces are not just managed, but conquered."}
{"paper_id": "452", "abstract": "In the realm of deep neural networks (DNNs), the quest for understanding their decision-making processes often leads us to the creation of saliency maps—visual representations that illuminate the most influential features contributing to a given prediction. Yet, these maps, while useful, are not the whole story. They lack the contextual depth that humans crave, failing to provide the nuanced, word-based explanations that resonate with our natural reasoning patterns.   To bridge this critical gap, we introduce a groundbreaking approach to explainable AI that operates on a multilevel framework, merging visual and linguistic dimensions. By harnessing the power of per-class attributes, our method crafts linguistic salient attributes alongside traditional saliency maps, resulting in explanations that are not only more human-like but also significantly more comprehensive.  We put our approach to the test across a diverse array of datasets, ranging from coarse-grained to fine-grained, and the results are compelling. Our method outshines existing state-of-the-art techniques, offering clearer and more insightful explanations that align closely with human intuition. In doing so, we pave the way for a new era of understanding in the complex world of DNNs, where clarity and comprehension reign supreme."}
{"paper_id": "453", "abstract": "In the realm of solving partial differential equations (PDEs), physics-informed neural networks (PINNs) have emerged as a formidable contender, wielding the power of deep learning to tackle the intricate puzzles of science and engineering. Yet, beneath this promise lies a shadow: the specter of spectral bias, a challenge that has proven elusive for even the most sophisticated PINNs. This bias, we argue, is not merely a nuisance but a fundamental limitation tied to the architecture of infinitely-wide networks, manifesting in the sluggish convergence of high-frequency modes during training.  To combat this formidable foe, we delve into the optimization landscape of PINNs, exploring the dynamics of gradient flow under the guidance of the gradient descent (GD) and gradient descent with momentum (GDM) optimizers. Our analysis reveals a surprising truth: while GDM does indeed mitigate the effects of spectral bias, it is the Adam optimizer that truly shines, wielding the power to accelerate the training process and significantly reduce the influence of spectral bias.  Through a series of rigorous numerical experiments, we validate our theoretical insights, showcasing the remarkable efficacy of Adam in enhancing the training of PINNs across a diverse array of PDEs. In this journey through the intricate interplay of mathematics and machine learning, we uncover not just strategies for triumph over spectral bias, but also the potential for deeper understanding in the quest for accurate solutions to the equations that govern our world."}
{"paper_id": "454", "abstract": "In the realm of neural networks, the prevailing paradigm has long been the pointwise activation, where a uniform function is applied to each dimension of the input independently. Yet, this paper dares to venture into uncharted territory, introducing a novel class of networks that embrace non-pointwise nonlinearities, which we have dubbed radial neural networks. At the heart of these networks lies the radial rescaling activation, a mechanism that transforms input vectors by scaling each component according to its distance from the origin, defined as: $$\\sigma(v) = \\lambda(\\|v\\|)v,$$ where $\\lambda$ is a scalar function of the norm.  Our exploration reveals that radial neural networks possess a remarkable trait: they can approximate any asymptotically affine function with a bounded width, a testament to their expressive power. Moreover, we unveil a lossless compression algorithm tailored for these networks, one that leverages the inherent symmetries present in the parameter space. This algorithm yields a compressed network, characterized by fewer neurons in each hidden layer, yet it maintains the integrity of the loss function across all training data.  To substantiate our claims, we present a series of experiments that not only validate our theoretical assertions but also illustrate the practical advantages of radial neural networks. In a world where innovation is key, our findings open new avenues for exploration and application, inviting researchers to reconsider the traditional boundaries of neural network design."}
{"paper_id": "455", "abstract": "In the realm of federated learning (FL), a tapestry of client heterogeneity and the art of local updates woven together create a unique optimization challenge. In this paper, we embark on a journey to unravel the training dynamics of FL through the lens of an analogy with mini-batch stochastic gradient descent (SGD)—a well-established stalwart in centralized optimization. Our exploration reveals two pivotal insights that illuminate the path forward:  First, we introduce the concept of client coherence, a nuanced understanding that encompasses both the local gradient coherence among clients and the heterogeneity coherence within the client pool itself. This coherence acts as a guiding thread, influencing the training dynamics of FL in profound ways.  Second, we delve into the efficacy of global weight shrinking (GWS) as a regularization technique, uncovering its potent role in bolstering the generalization capabilities of the global model. Our findings reveal that the optimal weight shrinking factor emerges from a delicate interplay of the global gradient's magnitude, the number of local epochs, and the degree of IID-ness among clients.  Armed with these insights, we present FEDAWO, a novel federated optimization algorithm that harmonizes global weight shrinking with attentive client aggregation. Through rigorous experimentation, we demonstrate that FEDAWO not only enhances the generalization performance of the global model but also achieves a reduction in communication rounds, paving the way for more efficient federated learning deployments."}
{"paper_id": "456", "abstract": "In the realm of natural language processing, the quest for accurate message classification and regression stands as a pivotal challenge, with profound implications for real-world applications. Take, for instance, the intricate task of routing tickets within a call center—here, the ability to swiftly and precisely categorize messages based on their content and context can mean the difference between efficient service and chaos. Yet, despite the wealth of available datasets and the fervent pursuit of solutions, the quest for a universally superior algorithm remains an unsolved riddle.   In this paper, we unveil a groundbreaking approach that seeks to transcend the limitations of existing methodologies. We introduce a modular transformer-based architecture, designed with distinct blocks that elegantly accommodate both textual and non-textual features. Our experiments, conducted across a diverse array of datasets, reveal a compelling narrative: our method not only competes with but often surpasses the current benchmarks in the realm of message classification. In doing so, we illuminate a path forward, demonstrating that by harnessing the full potential of both text and non-textual elements, we can achieve levels of accuracy previously thought unattainable."}
{"paper_id": "457", "abstract": "In the ever-evolving realm of video-language pre-training (VLP), a new frontier has emerged—one that seeks to democratize the process, making it accessible to all. In this paper, we unveil a groundbreaking approach that not only streamlines the pre-training of video representations but also enhances the quality of downstream tasks. Our strategy involves a dual assault on redundancy: first, by discarding redundant temporal clips and second, by eliminating the spatial redundancies inherent within each clip.  To achieve this, we harness the power of offline region features, a technique that has long been favored in image-text tasks for its ability to distill the essence of visual content into compact, meaningful representations. By employing these region features, we significantly reduce the computational burden of attention mechanisms, allowing our model to flourish with greater capacity and efficiency.  Moreover, we advocate for a “less is more” philosophy, emphasizing the importance of fine-grained cross-modality alignment regularization. This approach ensures that the relationships between visual and textual representations remain sharp and well-defined. Our experiments reveal that this regularization technique not only elevates the performance of our VLP model but also confers benefits to end-to-end methods that rely on raw video inputs.  In a world where data and time are precious commodities, our method shines, delivering state-of-the-art results across four downstream video-language retrieval tasks—all while utilizing only a fraction of the data and pre-training time traditionally required. This not only advances the field but also opens the door for more researchers to engage in the exciting realm of VLP."}
{"paper_id": "458", "abstract": "In the realm of machine learning, where the balance of privacy and collaboration is paramount, vertical federated learning (VFL) emerges as a beacon of hope. It offers a path to solving complex machine learning challenges while safeguarding the delicate tapestry of data privacy. Yet, the current landscape of VFL methods is largely confined to the straightforward terrains of single-level structures, leaving the more intricate realms of bilevel programming uncharted. Bilevel optimization (BO) stands as a powerful ally in tackling these multifaceted tasks, yet the application of existing BO techniques to VFL is fraught with peril. The direct computation of second-order derivatives and the approximation of the Hessian matrix not only strain computational resources but also open the door to the insidious leakage of feature privacy.  In response to this formidable challenge, we unveil a groundbreaking approach: the stochastic Bilevel optimization Method with a desirable JacoBian estImator (BAMBI). This innovative framework adeptly navigates the complexities of VFL by employing a zeroth-order Jacobian estimation technique, allowing for the computation of hypergradients with both privacy preservation and computational efficiency. Our theoretical analysis reveals that BAMBI maintains a convergence rate of $1/\\sqrt{K}$ for nonconvex-strongly-convex problems, a testament to its prowess without sacrificing the vital tenets of privacy.  However, our journey does not end there. Recognizing the equally critical need to safeguard label privacy, we introduce BAMBI-DP, a differentially private variant that fortifies our approach. Through rigorous proof, we demonstrate that BAMBI-DP adheres to $(\\varepsilon, 0)$-differential privacy with respect to labels, further solidifying our commitment to privacy.  To illustrate the practical implications of our methodologies, we delve into two illustrative applications: hyper-representation learning and hyperparameter tuning. Our experimental results shine a light on the effectiveness of BAMBI and BAMBI-DP, showcasing their potential to reshape the landscape of federated learning while protecting the sacred sanctum of data privacy."}
{"paper_id": "459", "abstract": "In the realm of multi-agent learning, where the intricacies of cooperation and competition dance in the shadows of strategic interactions, we delve into the complexities of Stackelberg games. Here, we unveil a novel decentralized algorithm designed for the online learning of these games, where players take turns, each one a pivotal moment in the unfolding narrative of their strategies. Our approach hinges on the elegant concept of no-regret algorithms, those steadfast companions of the single-player multi-armed bandit problem, which we harness to navigate the turbulent waters of learning in a multi-agent environment.  In this decentralized landscape, players are interconnected through a graph, bound by the threads of communication that allow them to share their observations with neighbors. Yet, the true magic lies in our analysis, which transcends the limitations of previous studies. We introduce the concept of joint pseudo-regret, a new metric that measures the collective performance of players, each of whom only possesses partial information about their shared environment. Our findings reveal that, despite the inherent challenges of decentralized learning, the cumulative joint pseudo-regret of our algorithm scales merely quadratically with the number of players. This, we argue, is a triumph, for it signifies that our approach not only accommodates the presence of communication delays but also thrives in the face of them.  Moreover, our algorithm exhibits a remarkable duality: it gracefully transitions between the stochastic and adversarial realms, adapting seamlessly to the uncertainty that lurks in the shadows. In doing so, we illuminate a path forward, one that promises to reshape our understanding of multi-agent learning in dynamic and complex environments."}
{"paper_id": "460", "abstract": "In the realm of dynamical systems, the quest for optimal control often feels like a hero's journey—a path fraught with challenges and steeped in complexity. The traditional numerical solvers, like the direct method, embark on a two-phase odyssey: first, they forge a surrogate model from the intricate tapestry of system dynamics, only to cast aside this creation in favor of a second phase that directly tackles the optimization of control variables. This approach, while noble in intent, comes at a steep price, sacrificing both speed and the coveted ability to generalize across diverse challenges.  Enter OptCtrlOP, our groundbreaking optimal control operator, a beacon of innovation in this landscape. By embracing the direct-mapping paradigm, OptCtrlOP learns to navigate the treacherous waters of optimal control problems with a single, fluid motion. It harnesses the power of Pontryagin's Maximum Principle, deftly transforming the optimization conundrum into a boundary value problem. This clever reformation not only streamlines the process but also paves the way for a remarkable reduction in computational demands—achieving a staggering 100 times speedup over traditional methods and an astonishing 10,000 times over the direct method.  But the true magic lies in OptCtrlOP's ability to generalize seamlessly across a spectrum of optimal control scenarios, all without the need for retraining. In a world where complexity reigns, OptCtrlOP stands as a testament to what is possible when innovation meets ingenuity."}
{"paper_id": "461", "abstract": "In the realm of federated learning (FL), a multitude of strategies have emerged, each claiming to enhance the efficiency of training deep neural networks (DNNs) across a vast landscape of clients. Yet, a critical oversight prevails: most of these approaches overlook the pivotal nature of the initial training epochs, often referred to as the critical learning (CL) periods. During these formative moments, the quality of the training data and the architecture of the model wield significant influence, setting the stage for the ultimate success of the learning endeavor.  In this paper, we unveil a groundbreaking framework for federated learning that embraces the intricacies of these CL periods, which we have dubbed FedCL. Our framework introduces an innovative adaptive client selection mechanism that intelligently identifies and engages with clients during these crucial epochs, ensuring that the learning process is not merely reactive but proactive. Through rigorous experimentation, we demonstrate that FedCL not only meets but surpasses the performance of existing state-of-the-art federated learning methods, particularly in scenarios characterized by limited data and a high degree of statistical heterogeneity. In doing so, we pave a new path forward, one where the nuances of federated learning are finally given the respect they deserve."}
{"paper_id": "462", "abstract": "In the realm of understanding complex scenes, we unveil OBPOSE, a groundbreaking unsupervised object-centric generative model that operates directly from RGB-D images or video. This innovative approach allows OBPOSE to unravel the intricacies of a scene into its fundamental components: objects and an implicit background. At the heart of OBPOSE lies a groundbreaking encoder design, which deftly disentangles the scene into two distinct slots. The first slot captures the essence of each object, while the second slot holds the overarching scene context.  What sets OBPOSE apart is its unique application of pose as an inductive bias, a concept that has largely been overlooked in the 3D realm. By leveraging the inherent asymmetries of an object's shape, OBPOSE adeptly infers its pose, enhancing the learning process for the \"what\" component in 3D. This clever strategy not only streamlines the training of the what component but also significantly reduces its variance, paving the way for superior performance in downstream tasks.  Our rigorous evaluations across three diverse datasets—Clevr, MultiShapeNet, and YCB—demonstrate that OBPOSE sets a new benchmark for unsupervised 3D scene inference, eclipsing the previous state-of-the-art, ObSuRF, by substantial margins. In doing so, OBPOSE not only advances the field but also redefines what is possible in the analysis of complex environments."}
{"paper_id": "463", "abstract": "In the realm of machine learning, where the quest for vast datasets often collides with the limitations of human expertise, crowdsourcing emerges as a beacon of hope. It offers a swift and cost-effective means to amass labels, transforming the landscape of supervised learning. Yet, the quality of these labels can be fraught with peril, tainted by the whims of unskilled or biased workers. To navigate this treacherous terrain, we turn to the principles of Item Response Theory, specifically the concept of the Area Under the Margin (AUM), a powerful tool for discerning the reliability of individual tasks.  In this paper, we unveil a groundbreaking generalization of the AUM, tailored for the complexities of crowdsourcing. This innovation, which we call the Weighted Area Under the Margin (WAUM), serves as a beacon of clarity in the fog of ambiguous tasks. It empowers us to pinpoint those elusive data points that, despite their labels, pose a threat to our model's ability to generalize. By harnessing the WAUM, we can deftly prune these harmful tasks from our datasets, paving the way for a more robust and reliable learning experience.  Our experiments, conducted on the CIFAR-10 and ImageNet datasets, illuminate the efficacy of the WAUM. We demonstrate its prowess in identifying and discarding these detrimental tasks, ultimately enhancing the accuracy of our models and bolstering their generalization capabilities. In this journey through the intricate tapestry of data and learning, the WAUM stands as a testament to the power of thoughtful analysis and innovation."}
{"paper_id": "464", "abstract": "In the realm of self-supervised learning (SSL), the quest for understanding the intricate dance of video data unfolds much like the unfolding of a narrative. Each frame, each clip, is a page in a book of experiences, and the challenge lies in capturing the essence of this visual tapestry without the crutch of labels. While many have ventured into this domain, harnessing the power of deep learning to extract meaningful representations from the chaotic flow of video clips, a crucial element often remains elusive: the semantic consistency that binds together the semantics of a given clip.  In this work, we embark on a journey inspired by the very fabric of human cognition. We posit that the self-awareness of semantic change serves as a beacon, illuminating the path to learning. By employing the prediction error (PE) as a guiding star, we weave a contrastive learning framework that models the nuanced semantics of video clips with precision. This approach not only enhances our understanding but also aligns our methods with the biorational principles that govern human learning.  But we do not stop there. Recognizing the vital role of representation reorganization in the human brain, we integrate prototypical contrastive learning into our framework. This innovative technique acts as a catalyst, reshaping the learned representations to foster stronger associations among perceptually similar semantics. The result? A retrieval performance that soars to new heights, outpacing previous methods in the realm of video retrieval.  To validate our approach, we put it to the test on the UCF101 dataset, where it shines with a remarkable 96.3% Top-1 video retrieval accuracy. Furthermore, our method demonstrates a remarkable adaptability, excelling in downstream tasks such as video action recognition. In this fusion of science and inspiration, we have crafted a tool that not only advances the field of SSL but also echoes the profound intricacies of human learning."}
{"paper_id": "465", "abstract": "In the realm of multi-agent systems, where complexity often veils cooperation, we embark on a quest to unravel the mysteries of learning effective policies in the face of sparse rewards, all while navigating the vast expanse of a large-scale environment. The challenges are formidable: the exponential growth of the joint observation-action space and the arduous nature of acquiring sufficient training trajectories. Traditional multi-agent reinforcement learning (MARL) algorithms, when wielded directly against such formidable foes, often falter, yielding agents that lack the necessary teamwork to thrive.  Enter the realm of automatic curriculum learning (ACL), a beacon of hope that illuminates the path to effective policy learning. By deftly crafting a sequence of tasks, a teacher guides a student, enhancing their capabilities through strategic task selection. Yet, as the student population burgeons, the teacher grapples with the daunting prospect of task non-stationarity, a challenge that threatens to undermine the learning process.  In this paper, we unveil a groundbreaking approach: the Skilled Population Curriculum (SPC). This innovative method empowers the student to learn a diverse array of skills across a spectrum of tasks, each characterized by varying numbers of agents. Drawing inspiration from the intricacies of real-world team sports, where players hone their skills through a series of progressively challenging tasks and collaborations, SPC transforms the learning journey.  At the heart of SPC lies a sophisticated teacher modeled as a contextual bandit. Here, we harness an RNN-based imitation model to represent the student's policies, weaving a tapestry of strategic guidance. Moreover, we introduce a population-invariant communication mechanism, where each agent's message is treated as an essential word in a larger sentence, allowing for seamless collaboration among an arbitrary number of agents.  Our empirical results speak volumes, showcasing SPC's remarkable ability to master a variety of cooperative tasks within the multi-particle environment (MPE) and the exhilarating 5vs5 competition of Google Research Football (GRF). In this unfolding narrative of learning and cooperation, SPC stands as a testament to the power of innovation and strategic design in the pursuit of multi-agent synergy."}
{"paper_id": "466", "abstract": "In the realm of deep learning, convolutional neural networks (CNNs) have emerged as powerful allies, particularly in the intricate dance of image classification. Yet, lurking in the shadows is a formidable challenge: the ever-present curse of dimensionality. This phenomenon, where the decay of generalization error with the number of training samples dwindles as the input dimension swells, threatens to overwhelm our best efforts. However, the success of CNNs in navigating high-dimensional landscapes suggests that they tap into the hidden structures inherent in the tasks they tackle.  In this exploration, we delve into the generalization capabilities of deep CNNs, wielding the tools of kernel regression and the elegant framework of the Neural Tangent Kernel (NTK). Our journey reveals a striking truth: deep CNNs possess an uncanny ability to adapt to the spatial hierarchies embedded within the very tasks they endeavor to understand. This adaptivity translates into a remarkable advantage, as it allows deep CNNs to achieve generalization error rates that are not only superior to those of their fully-connected counterparts but also tantalizingly close to the coveted Bayes-optimal rates.  To substantiate our claims, we present a robust theoretical framework alongside a series of extensive numerical experiments. The results shine a light on the intricate interplay between the architecture of deep CNNs and the spatial structures of the tasks they seek to master. In this unfolding narrative, we uncover a path forward, one that promises to reshape our understanding of how machines learn from the complexities of the world around them."}
{"paper_id": "467", "abstract": "In the realm of instance segmentation, the traditional paradigms often confine themselves to a select few classes, neglecting the vast expanse of the open-world where new and uncharted categories lurk in the shadows. To address this challenge, we present a groundbreaking approach: the Transformer-based Open-world Instance Segmentation (TOIS) method. At the heart of our innovation lies a cross-task consistency loss, a powerful tool designed to counteract the pitfalls of incomplete instance annotations—a common foe in open-world scenarios.  This loss acts as a guiding light, ensuring that our predictions for instance masks and a foreground map remain harmonious and consistent. By doing so, it deftly mitigates the detrimental effects of those elusive instances that slip through the cracks of annotation. Our experiments reveal that this consistency loss is not merely a Band-Aid solution; it shines brightest in environments where annotations are sparse, proving to be a robust ally in the face of uncertainty.  But we do not stop there. We have also extended our TOIS framework into the realm of semi-supervised learning, unlocking the potential to harness the power of unlabeled images and further enhance our open-world segmentation capabilities. The results speak for themselves: our method not only achieves state-of-the-art performance in fully-supervised settings but also demonstrates a remarkable ability to thrive in the semi-supervised landscape, all while navigating the complexities of open-world segmentation. In this way, we pave a new path forward, illuminating the dark corners of segmentation in a world brimming with possibility and unpredictability."}
{"paper_id": "468", "abstract": "In the realm of reinforcement learning, the quest for policies that not only maximize rewards but also adhere to critical constraints is akin to a hero balancing the weight of their duties. The challenge of constrained Markov decision processes (CMDPs) has long been a subject of scholarly inquiry, yet it is often the test environments that prove to be the true试金石, revealing the flaws of policies trained on seemingly idyllic simulations. This paper embarks on a journey to tackle the constrained RL conundrum in the face of uncertainty, employing a pessimistic approach that prepares us for the worst-case scenarios posed by model discrepancies.  We delve into the intricacies of the constrained RL problem, revealing that the duality gap can expand in the presence of uncertainty, a stark contrast to the deterministic landscape of non-robust CMDPs. To navigate this treacherous terrain, we introduce a robust primal-dual algorithm, designed to converge to stationary points, providing a beacon of hope in the fog of uncertainty. Our exploration does not end there; we extend our findings to the widely-adopted $\\delta$-contamination model, unveiling a novel actor-critic algorithm that not only converges but also ensures robust feasibility.  Through rigorous analysis and compelling empirical results, we illuminate the path forward, demonstrating that our algorithms can withstand the trials of uncertain environments while maintaining performance and adherence to constraints. In this endeavor, we forge a new understanding of how to wield the power of reinforcement learning in the face of adversity."}
{"paper_id": "469", "abstract": "In the realm of reinforcement learning (RL), the prevailing wisdom has long favored the use of policy gradient methods, particularly those employing gradient descent, as the cornerstone for solving RL challenges. Yet, beneath this veneer of convention lies a deeper truth: the convergence of these policy gradient methods hinges on a delicate assumption about the underlying system dynamics—specifically, their stability. This assumption is often overlooked, yet it plays a pivotal role in the efficacy of policy optimization.  In this exploration, we delve into the intricacies of unstable RL problems, revealing that a significant barrier to rapid convergence stems from the large spectral radius of the Hessian matrix. To address this, we introduce a novel logarithmic mapping technique designed to mitigate the effects of this spectral radius. Our theoretical framework, bolstered by rigorous proofs, demonstrates the superiority of this logarithmic mapping.  To ground our findings in practicality, we present a finite horizon linear quadratic regulator (LQR) problem as a case study, illustrating how our approach enhances convergence. Moreover, we extend our analysis to more complex, nonlinear scenarios, employing neural network-based policies. The results from our experiments not only validate our theoretical predictions but also showcase the robust performance of our logarithmic mapping technique in accelerating convergence across a spectrum of RL benchmarks."}
{"paper_id": "470", "abstract": "In the realm of deep learning, where the shadows of opacity and black-box decision-making loom large, we embark on a quest to illuminate the path with a novel approach: the Sparse Low-Dimensional Decision (SLDD) model. This creation is forged from the depths of a sparse linear classifier, drawing its strength from a select few features that together wield the power of classification. Our method employs a clever combination of $L_1$-regularization and a hinge loss to shape a sparse linear decision boundary, honing in on a minimal subset of features that are both sparse and low-dimensional.  But we do not stop there. To enrich our model further, we introduce a groundbreaking feature diversity loss, designed to foster a rich tapestry of diverse features. This innovation not only enhances our performance in the sparse linear regime but also ensures that our model remains resilient against overfitting.  Through our efforts, we unveil a series of sparse low-dimensional decision models that stand tall among their peers, achieving competitive accuracy on a variety of image classification benchmarks. In a world where understanding is paramount, our SLDD models emerge as beacons of clarity, bridging the gap between machine learning and human comprehension."}
{"paper_id": "471", "abstract": "In the realm of aerial navigation, the quest for precise trajectory tracking in unmanned aerial vehicles (UAVs) often collides with the unpredictable whims of the environment. The wind, a capricious ally, can send even the most adeptly controlled UAV off course, its effects manifesting as aerodynamic disturbances that are both elusive and challenging to model. In this paper, we unveil a groundbreaking adaptive flight control strategy, aptly named OoD-Control, designed to empower UAVs to navigate these turbulent waters with grace and accuracy, even when faced with the unexpected.  Unlike traditional data-driven approaches that rely heavily on the I.I.D. assumption, our OoD-Control method boldly embraces the notion of domain shifts in environmental conditions, offering robust performance guarantees that stand tall against the unpredictability of the world around us. Through rigorous theoretical analysis and compelling simulated results, we demonstrate that our algorithm not only meets but exceeds the challenges posed by varying aerodynamic conditions. In doing so, we pave the way for a new era of adaptive flight control, where UAVs can soar with confidence, regardless of the winds that may blow."}
{"paper_id": "472", "abstract": "In the realm of visual storytelling, the art of talking head video generation stands as a beacon of innovation, enabling the creation of lifelike avatars that bring narratives to vivid fruition. In this endeavor, we unveil a groundbreaking approach: the Memory Compensation Network (MCNet). This innovative framework harnesses the power of global facial priors, adeptly compensating for the inherent ambiguities that arise from the synthesis of dynamic head motions with the static essence of a source image.   At the heart of MCNet lies a global spatial meta memory bank, a repository of facial representations gleaned from the collective diversity of training images. This meta memory serves as a steadfast ally, providing essential compensatory features that enhance the generation process. To navigate the intricate landscape of facial structures, we introduce an Implicit Scale Conditioned Memory Module (ISCM). This module deftly extracts scale representations from facial keypoints, allowing for a nuanced query of the meta memory bank that adapts to the unique scales of individual faces.   The result? A refined feature map, meticulously compensated to address the ambiguities that often plague the generation of talking head videos. Our extensive experiments, conducted on both VoxCeleb and CelebV datasets, reveal the remarkable efficacy of our approach. The generated videos not only surpass the state-of-the-art in terms of quality but also demonstrate a striking ability to generalize across various face identities. In this fusion of art and technology, we invite you to witness the birth of lifelike avatars that transcend the boundaries of imagination."}
{"paper_id": "473", "abstract": "In the realm of reinforcement learning, a formidable challenge looms: the vast and intricate action spaces that often defy our attempts to navigate them. These spaces, whether continuous or vast and discrete, present a dual dilemma. First, the sheer volume of potential actions renders exhaustive enumeration an insurmountable task. Second, the very nature of the actions themselves may be complex, noisy, or uniquely tailored to the demands of the task at hand. This complexity means that the action representations often bear little resemblance to their actual effects within the environment.  To tackle this challenge, we propose a novel approach: the infusion of listwise reinforcement learning (LW-RL) into the heart of action retrieval. By reframing the retrieval process as a listwise RL endeavor, we unlock new possibilities for learning and adaptability. This innovative perspective allows us to incrementally construct a list of candidate actions, drawing from a rich pool of potential options without the burden of enumerating every conceivable combination.  Enter FLAIR—Flexible Listwise ActIon Retrieval—a groundbreaking framework that empowers agents to learn flexible and efficient decision-making in the face of vast action spaces. FLAIR operates by training a series of actor-critic pairs, each tasked with generating a single action that, when woven into the fabric of the current list, maximizes the expected environment reward. Through this method, we demonstrate that agents trained within the FLAIR framework can adeptly learn to retrieve diverse lists of actions, paving the way for robust and adaptive decision-making.  Our findings, drawn from a variety of environments including a novel simulated robotics task, a recommender system, and the widely recognized MineRL Jumping task, showcase the remarkable efficacy of our approach. In a world brimming with complexity, FLAIR stands as a beacon of innovation, guiding us toward solutions that were once thought impossible."}
{"paper_id": "474", "abstract": "In the realm of deep learning, where the shadows of adversarial attacks loom large, we embark on a quest to unravel the intricate tapestry of relationships between semantic word embeddings and the resilience of deep neural networks. Our exploration reveals a compelling truth: as models become more robust, the threads of correlation between their visual representations and semantic word vectors woven tighter together. This discovery leads us to a pivotal insight—adversarial training, through its imposition of geometric constraints, serves as a bridge, aligning the manifold of visual representations with the structured realm of word vectors.  Armed with this understanding, we introduce the Semantic Constraint Adversarial Robust Learning (SCARL) framework. SCARL boldly confronts the challenges posed by distribution shifts, employing a dual strategy: first, by maximizing the mutual information between visual representations and semantic word vectors to strengthen their interconnections, and second, by imposing geometric constraints to further align these representations within their respective manifolds.  Our rigorous validation of SCARL spans three esteemed image classification benchmarks—CIFAR-10/100 and ImageNet—across a diverse array of neural network architectures, including ResNet, DenseNet, and VGG. The results of our experiments shine brightly, demonstrating that SCARL not only enhances adversarial robustness but does so with remarkable efficiency, outpacing several state-of-the-art methods in the process. In this journey, we have not merely sought to improve; we have forged a path toward a more resilient future in deep learning."}
{"paper_id": "475", "abstract": "In the realm of machine learning, the advent of large-scale pretrained models, such as CLIP, has ushered in a new era of remarkable performance across a multitude of tasks. Yet, the practical deployment of these behemoths in real-world scenarios presents a formidable challenge, as their demands for computational resources and memory often clash with the constraints of mobile devices. To navigate this conundrum, we delve into the intriguing possibility of leveraging the knowledge housed within these expansive models to enhance the capabilities of smaller, task-specific networks.  In our exploration, we scrutinize the nuances of knowledge transfer from CLIP to lightweight models, unveiling both the strengths and limitations of this approach. Our findings reveal a critical insight: the direct application of knowledge distillation from CLIP often falls short, yielding results that underperform those achieved through traditional methods. To surmount this obstacle, we introduce a novel strategy—fine-tuning CLIP itself to elevate its performance on the specific task at hand, thereby establishing a new benchmark for accuracy that serves as our guiding light in the knowledge distillation process.  This fine-tuning of CLIP proves to be a game-changer, enabling us to extract superior knowledge and significantly bolster the accuracy of lightweight models, even in the face of limited training data. Our results, bolstered by a quantitative analysis of the output distributions from teacher networks, illuminate the unique advantages of CLIP in the realm of knowledge distillation. In doing so, we not only advance the capabilities of lightweight models but also pave the way for a future where the power of large-scale pretrained models can be harnessed without sacrificing efficiency."}
{"paper_id": "476", "abstract": "In the realm of artificial intelligence, the quest for high-level knowledge has long been a challenge, often overshadowed by the vast ocean of data-driven learning. Yet, in this paper, we embark on a novel journey, merging the intricate structures of logic with the profound capabilities of deep neural networks. Our focus is on the classification of indoor scenes, a domain fraught with complexity due to the rich tapestry of objects that weave through each image.  To tackle this, we introduce a groundbreaking framework that intertwines the early fusion of visual logical knowledge with the traditional image features, creating a harmonious blend of structure and form. At the heart of our approach lies a 'if-then' logical knowledge system, meticulously crafted from the contextual embeddings of words gleaned from a wealth of indoor scene images. This system is not merely an accumulation of facts; it is a meticulously curated collection of 'if-then' rules, each one meticulously extracted from a meticulously annotated dataset.  But we do not stop there. To bridge the gap between the abstract realms of logic and the concrete world of images, we propose a novel embedding method. This technique imbues each 'if-then' rule with a unique representation, allowing for a seamless integration that enhances the overall classification performance. The result is a model that not only recognizes the objects present in an image but also understands the intricate relationships that define the scene as a whole.  Through rigorous experimentation, we demonstrate that our hybrid model outshines traditional image classification methods, achieving a remarkable 10% increase in accuracy. In doing so, we pave the way for a new era of understanding, where the fusion of logic and neural networks unlocks the potential for more nuanced and intelligent image analysis."}
{"paper_id": "477", "abstract": "In the realm of video recognition, the quest for high accuracy often collides with the specter of overfitting, particularly in the face of limited training samples and the inherent challenges of temporal modeling. In this paper, we unveil a novel data augmentation technique we call Ghost Motion (GM), designed to bolster the generalization capabilities of video recognition models. At its core, GM operates by shifting the temporal order of video channels, a simple yet powerful maneuver that creates a “ghost” video through interpolation. This shifting diffuses the motion patterns from salient frames into their less dynamic counterparts, enriching the overall representational capacity of the model.  Moreover, we introduce a temperature scaling technique that further mitigates overfitting by tempering the model's confidence in its predictions. Our experimental results, drawn from a diverse array of datasets and baseline methods, demonstrate that GM not only enhances performance but does so with minimal computational overhead. We invite you to explore our findings and the code, which will be made available at https://github.com/XingangPan/Ghost-Motion."}
{"paper_id": "478", "abstract": "In the realm of graph neural networks (GNNs), the quest for efficient minibatch training on vast graphs presents a formidable challenge. The very essence of GNNs hinges on the intricate dance of message passing, a delicate interplay that unfolds across the edges of a graph, layer by layer. Yet, as we delve deeper, we encounter a conundrum: the vast expanse of the l-hop neighborhood, a phenomenon we call the Neighborhood Explosion Phenomenon (NEP). This leads to a perplexing situation where the computed node embeddings lose their connection to the very l-hop neighborhood they were meant to represent.  To navigate this treacherous terrain, researchers have turned their attention to subgraph sampling, a strategy that seeks to approximate these elusive l-hop neighborhoods. Traditionally, methods have relied on independent and recursive sampling of nodes or layers, but these approaches often fall short, either sacrificing the quality of the embeddings or burdening the system with excessive computational demands.  In this paper, we unveil a groundbreaking sampling algorithm, LABOR, a synthesis of neighbor and layer sampling techniques that harnesses the power of Poisson Sampling. LABOR deftly intertwines the sampling processes of a given set of seed nodes, creating a rich tapestry of overlap among the sampled vertices from each seed. This innovative approach not only slashes the computational and communication overhead by a remarkable 7 times but also dramatically reduces memory usage.  Our experiments reveal that LABOR stands shoulder to shoulder with the best of its contemporaries, outperforming both neighbor and layer sampling methods. Notably, it allows for a staggering 112 times increase in batch size while maintaining the same number of sampled vertices, all without sacrificing performance. In this way, LABOR heralds a new era in the efficient training of GNNs on large-scale graphs, paving the way for deeper understanding and broader applications in the realm of graph-based learning."}
{"paper_id": "479", "abstract": "In the realm of convolutional neural networks (CNNs), a technique as simple as padding has emerged as a pivotal element, wielding the power to profoundly influence model behavior. Yet, the prevailing wisdom has favored the humble zero-padding, perhaps due to its ease of implementation and computational efficiency. However, recent investigations (Islam* et al., 2020; Islam et al., 2021b; Kayhan & Gemert, 2020; Innamorati et al., 2020) have unveiled a troubling truth: the positional information embedded within padding can inadvertently disrupt other critical sources of position-sensitive cues, leading to unintended consequences and a decline in performance across various vision tasks (Ge et al., 2022; Alguacil et al., 2021; Islam et al., 2021a).  In response to this revelation, we embark on a thorough examination of the phenomenon of positional encoding, particularly as it relates to the widely-used padding schemes in CNNs. Our exploration hinges on the development of reliable metrics to detect and quantify the strength of positional information introduced by padding. We uncover a fundamental flaw in the existing evaluation methods, specifically the high variance observed in the metrics proposed by PosENet (Islam* et al., 2020) and the design inconsistencies within F-Conv’s Border Handling Variants (BHV) test.  To navigate the complexities of positional encoding, we introduce a novel approach: the Optimal Padding Scheme (OPS). This method allows us to extract a consistent and discernible pattern, which we term the Positional Pattern from Padding (PPP). By employing the distributional differences between optimally-padded and algorithmically-padded features, we define two robust metrics to measure the strength of PPP from a signal-to-noise perspective. Our findings reveal that these metrics exhibit remarkable consistency and low variance across various settings, including different models, padding schemes, and datasets.  Armed with our reliable metrics, we delve into a series of experiments to unravel the characteristics of PPP. Our results demonstrate that models adeptly circumvent the stochastic nature of our designed padding scheme, purposefully constructing PPPs to enhance their training efficiency. Furthermore, we observe that the PPPs of pretrained networks significantly outshine those in their initial states, underscoring the critical importance of unbiased training procedures in mitigating the detrimental effects of positional information in CNNs."}
{"paper_id": "480", "abstract": "In the realm of robotics, the quest for long-horizon policies in intricate physical environments stands as a formidable challenge, particularly for Reinforcement Learning (RL) methodologies. The sheer vastness of the state and action spaces demands an abundance of samples to forge effective policies for a myriad of tasks. A promising strategy emerges from the realm of classical robotics, where a high-level planner crafts an abstract trajectory within a simplified state space, while a low-level agent deftly executes these plans within the tangible confines of the physical world.  In this work, we embrace the philosophy of abstract-to-executable, advancing the learning-based approach with a two-level framework that enhances generalization to novel tasks. Traditionally, the alignment between high-level and low-level states has been a rigid necessity, complicating the adaptation of abstract trajectories to executable actions. However, we propose a groundbreaking solution: TRajectory TRanslation, or TR 2. This innovative learning-based framework adeptly translates abstract trajectories into executable forms for unseen tasks during inference.   TR 2 operates without the constraints of frame-to-frame alignment between abstract and executable trajectories, offering unparalleled flexibility in high-level agent design and abstract trajectory generation. Our approach not only facilitates seamless generalization across tasks but also demonstrates remarkable resilience against unintended deviations or errors in execution. Through rigorous evaluation across three manipulation tasks and a navigation-based challenge, our method consistently outperforms baseline strategies, showcasing its prowess in achieving one-shot generalization to new tasks.  To ground our findings in reality, we also conducted real-world experiments in the Block Stacking task, illuminating the robustness of our approach even amidst the unpredictability of physical interactions. For a visual demonstration of our capabilities, please visit our project page at https://blockworlds.github.io."}
{"paper_id": "481", "abstract": "In the realm of machine learning, where algorithms often operate in the shadows of complexity, the quest for understanding their decisions becomes paramount. Enter the kaBEDONN, a groundbreaking approach that seeks to illuminate the black box of deep neural networks through the power of relevant data. This innovative method constructs an ordered neural network, meticulously arranging representative data samples into a hierarchical structure. Each node in this intricate architecture is a training data point, selected for its ability to resonate with the input data, x, eliciting a strong response from the network.  The kaBEDONN not only provides a clear, visual explanation for a given prediction but also empowers users with the ability to delve deeper, exploring \"similar\" data points that further elucidate the model's reasoning. Moreover, it offers a dynamic platform for developers, enabling them to refine explanations in real-time through user feedback. This interplay between user and developer creates a rich environment for continuous improvement and adaptation.  Our experiments, conducted on the esteemed CIFAR10 and ImageNet datasets, reveal the kaBEDONN's remarkable prowess, achieving an impressive test accuracy of 94.4% and 73.8%, respectively. In a world where clarity and trust are essential, the kaBEDONN stands as a beacon of transparency, guiding us through the intricate landscape of machine learning."}
{"paper_id": "482", "abstract": "In the realm of reinforcement learning, the quest for mastering sequential decision-making hinges heavily on the art of value estimation. At the heart of this endeavor lies the elusive fixed point of the Bellman operator, a concept that has long captivated researchers. Yet, the path to this fixed point is fraught with challenges, particularly when we must rely on sampled data to approximate our journey. This reliance often leads to a sluggish convergence, leaving us yearning for a more efficient way forward.  In this paper, we unveil a groundbreaking approach: the projected Bellman operator (PBO). This innovative operator reimagines the process of value estimation, drawing upon sampled data to learn its form. Once this learning is complete, the PBO becomes a powerful ally, enabling us to generate a chain of updated parameters without the need for further samples. This not only enhances our computational efficiency but also opens new avenues for exploration in the field.  Our exploration of the PBO reveals its versatility, accommodating both discrete and continuous action-value function approximations. We delve into its advantages across a spectrum of RL challenges, including the complexities of continuous control and the intricacies of high-dimensional state spaces. Through rigorous empirical analysis, we demonstrate the prowess of our PBO-based algorithm, showcasing its performance against established baselines in both discrete and continuous action spaces.  In conclusion, we reflect on the broader implications of our findings, considering the potential of the PBO as a tool for tackling the intricate fixed-point problems that have long plagued the field of reinforcement learning. With this work, we aim to pave the way for future advancements, inviting fellow researchers to join us on this exciting journey."}
{"paper_id": "483", "abstract": "In the realm of text-to-image synthesis, the advent of models like DALL-E 2 has sparked both awe and concern. These remarkable systems, trained on vast troves of public data, possess the uncanny ability to conjure images from mere descriptions. Yet, beneath this veneer of sophistication lies a troubling truth: these models imbibe the biases inherent in the very data they consume. In our exploration, we unveil a particularly insidious vulnerability. By substituting a single character in a textual prompt with a visually similar non-Latin homoglyph, we can steer the generated imagery in unexpected directions. This manipulation, subtle to the naked eye, allows an attacker to subtly warp the model's output, leading to misleading results that undermine perceived quality. Our findings, drawn from a diverse array of models—including DALL-E 2, Stable Diffusion, and CLIP—and spanning a multitude of Unicode scripts, reveal a consistent pattern: a single homoglyph can wield significant influence, imposing cultural biases and, in some cases, rendering the image generation process itself irrelevant. This revelation raises urgent questions about the nature of these models and the biases that shape their outputs. As we navigate this complex landscape, it becomes clear that understanding these nuances is paramount for the responsible deployment of such technologies."}
{"paper_id": "484", "abstract": "In the realm of understanding the intricate dance of cause and effect, we embark on a quest to unravel the relationships hidden within high-dimensional data. Our approach is both elegant and powerful: we harness the principles of Additive Noise Models (ANMs) and the prowess of deep learning. By framing our exploration as a variational inference challenge, we unveil a novel method that learns these ANMs with remarkable efficiency.  At the heart of our innovation lies a clever application of automatic differentiation, which enables us to approximate the complex joint distribution of our data with a Gaussian model, complete with a sparse covariance matrix that deftly captures the essence of causality. But we do not stop there. Recognizing the limitations of linearity, we introduce a groundbreaking technique that allows us to extend our ANMs to accommodate non-linear relationships, ensuring that our model can adapt to the myriad complexities of real-world phenomena.  To validate our approach, we delve into a series of experiments, first with a synthetic image dataset, where our method shines, accurately inferring the latent variables that govern the data. Next, we turn our attention to a high-dimensional video game dataset, further solidifying our claims with compelling results. Through this work, we not only advance the field of causal discovery but also pave the way for a deeper understanding of the causal structures that underpin our world."}
{"paper_id": "485", "abstract": "In the realm of computer vision, the quest to discern the existence of objects hinges crucially on their unique visual signatures. To tackle this challenge, we unveil a novel approach: the hierarchical part-whole attention mechanism, affectionately dubbed HiPWA. This innovative method constructs a multi-level representation of objects, weaving together the intricate threads of compositional, semantic, and contextual visual information.  At the heart of HiPWA lies a hierarchical structure that organizes an object into three distinct levels: body parts, the complete body, and the expansive union area that encompasses all objects within a given frame. This design allows us to harness the salient features of the body while mitigating the impact of contextual noise—elements that, while present, do not belong to the primary subject of interest.  To bring this vision to life, we integrate the hierarchical representation with an attention mechanism inspired by the principles of transformers. This fusion enables the extraction of discriminative visual representations tailored to the objects of our focus. Our method is built upon a straightforward yet effective baseline model, designed to be both lightweight and efficient.  Through rigorous experimentation on established multi-object tracking datasets, we demonstrate the prowess of HiPWA, achieving performance that stands shoulder to shoulder with, and in some cases surpasses, the leading transformer-based methodologies in the field. In this way, we pave a new path forward in the pursuit of accurate and efficient object recognition."}
{"paper_id": "486", "abstract": "In the realm of Natural Language Processing, where the arcane art of language modeling wields immense power, we find ourselves at a crossroads. The vast, uncharted territories of human-written data have birthed a multitude of large-scale Pre-Trained Language Models (PTLMs), each a testament to the ingenuity of modern machine learning. Yet, lurking in the shadows of these impressive achievements are representational harms—insidious biases that threaten to undermine the very fabric of fairness and equity in our society.  In this exploration, we embark on a journey to illuminate these hidden biases, focusing on the way PTLMs associate negative connotations with marginalized groups. Our quest involves the creation of a novel metric, designed to measure the representational harms of 13 distinct marginalized demographics within the training datasets of 24 prominent PTLMs. Through our findings, we unveil a troubling truth: the majority of these models exhibit a concerning tendency to perpetuate harmful stereotypes.  Moreover, our analysis reveals a striking correlation between the magnitude of these representational harms and the performance of existing fairness metrics, particularly in the realms of sentiment and morality. This intricate relationship underscores the urgent need for a reevaluation of our approaches to fairness in language modeling. As we stand at this pivotal moment, we are compelled to ask: how can we reshape our methodologies to align more closely with the values of justice and equity that we aspire to uphold?"}
{"paper_id": "487", "abstract": "In the realm of machine learning, where the shadows of data distribution shifts loom large, we embark on a quest to unravel the resilience of self-supervised contrastive learning (CL) and its counterpart, supervised learning (SL). Our exploration is fueled by a diverse tapestry of data distribution corruptions, each thread woven from the intricate designs of prior research. Through a series of rigorous experiments, we delve into the downstream robustness of pre-trained models, navigating the treacherous waters of altered data distributions.  What we uncover is both surprising and profound. Self-supervised contrastive learning emerges as a steadfast ally, exhibiting remarkable resilience against a multitude of data distribution shifts. Yet, as we scrutinize the nuances of various CL algorithms, we find that their robustness can diverge dramatically. For instance, while contrastive learning thrives under the weight of dataset-level corruptions, it falters significantly in the face of more subtle, pixel-level alterations.  To illuminate these findings, we delve into the learning dynamics of both CL and SL, employing a multi-faceted approach that includes an analysis of feature space metrics and the examination of attention maps. Our investigation reveals that CL places a heightened emphasis on spatial information during the pre-training phase, a reliance that becomes a double-edged sword. On one hand, this focus sharpens the model's sensitivity to spatial structures, leaving it vulnerable when these patterns are disrupted. On the other, it underscores the critical role of data augmentation in fostering spatial coherence, a necessity that underscores the intricate dance between pre-processing and learning.  Armed with these insights, we propose a novel regularization technique designed to bolster the downstream robustness of supervised pre-training. In doing so, we not only fortify the defenses of our models against the capricious shifts in data distributions but also pave the way for a deeper understanding of the interplay between learning paradigms and the robustness they bestow."}
{"paper_id": "488", "abstract": "In the realm of classification, where the balance of speed and accuracy is paramount, multi-stage systems emerge as a beacon of efficiency. These intricate architectures deftly sift through data, employing a series of classifiers that work in tandem to deliver swift decisions. Yet, the traditional approach often hinges on a straightforward majority vote among these classifiers, a method that, while effective, falls short of maximizing their collective potential.   In this paper, we unveil a groundbreaking training framework designed to forge unprecedented connections between classifiers within a two-stage classification system. Our innovative approach involves a pre-classifier, a lightweight champion that is trained under the tutelage of a more substantial main-classifier. By doing so, we unlock the pre-classifier's full potential, allowing it to learn with purpose and intent.  We rigorously test our method on two widely recognized datasets, demonstrating that our framework not only enhances performance but also shines in scenarios with limited data—what we term few-shot environments. The results speak volumes, showcasing a significant leap forward in the art of classification, where speed and accuracy can coexist harmoniously."}
{"paper_id": "489", "abstract": "In the realm of reinforcement learning, the quest for effective policies often hinges on the art of crafting a diverse array of tasks. Yet, the intricacies of the real world present formidable challenges; the very nature of the tasks needed can be elusive, if not downright impossible, to pinpoint. Enter the realm of curriculum generation, where a clever teacher emerges, learning to forge tasks that guide a student agent toward mastery. Traditionally, teachers have been rewarded based on the regret experienced by the student, a measure of the difference in performance between the student and a hypothetical anti-student. However, we propose a fresh perspective: the teacher should be incentivized to create tasks that reside within the student's zone of proximal development (ZPD). This innovative approach ensures that the generated tasks are not only appropriately challenging but also serve to accelerate the student's learning journey.  To bring this concept to life, we introduce ZONE, a robust framework that delineates two essential techniques for teachers to navigate the ZPD. The first technique, REJECT,果断地摒弃那些难度不合适的任务，代之以更合适的替代品。第二项技术，ACCEPT，鼓励教师主动接纳那些难度适中的任务，从而进一步优化学生的训练体验。我们以两个备受瞩目的多智能体强化学习算法——PAIRED和Goal GAN为例，将ZPD的理论付诸实践。实验结果令人振奋：在连续控制任务中，我们的方法在多个经典多智能体任务上展现出色的性能，超越了现有的教学策略。这一突破不仅为多智能体强化学习的曲阜之路增添了亮色，也为未来的教学策略提供了新的思考方向。"}
{"paper_id": "490", "abstract": "In the ever-evolving landscape of Natural Language Processing, the advent of BERT has sparked a revolution, leading to a proliferation of BERT-style models that have become the lifeblood of numerous downstream tasks. Yet, lurking in the shadows of this innovation is a formidable challenge: the ever-present specter of redundancy. From the intricate web of attention heads to the vast expanse of learnable parameters and the sprawling layers of these models, opportunities for redundancy abound. As a result, researchers have turned their attention to compactification techniques, with Knowledge Distillation (KD) emerging as a powerful ally in the quest for efficiency.  In this paper, we delve into the realm of KD-based compression methods, particularly focusing on the ensemble of multiple teachers. While the idea of harnessing the collective wisdom of an ensemble is compelling, it often falls short, yielding underwhelming results when compared to the potential of a singular teacher. We posit that this shortfall can be attributed to two critical factors: first, the loss of diversity that occurs when distilled outputs converge, and second, the capacity gap that exists between the robust teachers and the student model itself.  To address these challenges, we introduce AutoSKDBERT, a groundbreaking approach that introduces a stochastic teacher selection mechanism, elegantly modeled as a categorical distribution. This innovative method allows us to learn the optimal distribution in a differentiable manner, effectively navigating the complexities of our task. Moreover, we propose a two-phase optimization framework, complemented by a teacher selection strategy, designed to identify and leverage effective teachers while refining the categorical distribution.  Our extensive experiments, conducted on the GLUE benchmark and the CIFAR-100 dataset, reveal the formidable capabilities of AutoSKDBERT, showcasing its ability to distill knowledge with remarkable efficiency. In a world where every detail matters, our findings illuminate a path forward, one where the power of stochastic teacher selection and robust optimization can transform the landscape of model compression."}
{"paper_id": "491", "abstract": "In the realm of machine learning, where the quest for universal models often leads to perilous entanglements, we unveil a novel approach to domain generalization (DG) that seeks to untangle the intricate web of domain-invariant and domain-specific representations. Our strategy hinges on a straightforward yet powerful concept: by imposing a regularization term that demands independence between these two realms within a dual-branching network, we can foster the growth of domain-invariant features that remain steadfast against the capricious shifts of domain shifts during inference.  Yet, our journey does not end there. We delve into the depths of feature independence, employing the Hilbert-Schmidt Information Criterion (HSIC) as our metric. To further amplify the potency of our method, we introduce a domain augmentation technique that compels the domain-invariant features to embrace a rich diversity of domain-specific representations. In doing so, we create a harmonious balance where the target branch and the domain branch engage in a dance of mutual invariance, each maintaining its integrity amidst the other's fluctuations.  The results of our endeavors speak volumes, as our method outshines the current state-of-the-art, achieving a remarkable 10.2% improvement in accuracy over the previous best on the omniglot DG benchmark. This success not only underscores the efficacy of our approach but also illuminates a path forward in the ongoing battle against the chaos of domain shifts."}
{"paper_id": "492", "abstract": "In the realm of self-supervised learning (SSL), a powerful technique has emerged, enabling the generation of high-quality pseudo labels from pretext tasks. These labels, in turn, empower the training of new SSL models without the need for manual annotations. Yet, the path to harnessing the full potential of these pretrained models often leads to a daunting demand for extensive training epochs, a challenge that can strain even the most robust computational resources.   In this endeavor, we embark on a quest to explore the concept of sustainable SSL, aiming to leverage the wisdom of existing pretrained models while also surpassing their capabilities. To achieve this, we introduce a novel approach: Target-Enhanced Conditional (TEC) mask-reconstruction. This innovative method not only refines the reconstruction targets derived from the base model but also employs conditional adapters that allow the new model to learn in a manner that complements the base, fostering a spirit of cooperation rather than competition.  Our experiments reveal a remarkable truth: TEC can elevate the performance of pretrained SSL models by impressive margins, even when trained from scratch with minimal epochs. For instance, by utilizing a pretrained MAE model, TEC enhances accuracy by 1.0% on ImageNet, all while requiring only half the training epochs as MAE undergoes its full 1600 epochs of training. Furthermore, when paired with a 300-epoch-trained MAE, TEC achieves a 1.4% improvement in accuracy after merely 100 additional epochs of training.  With these findings, we take a significant step toward the realization of sustainable SSL, paving the way for future advancements in this exciting field. We eagerly anticipate the reactions of the community and welcome discussions on our project page."}
{"paper_id": "493", "abstract": "In the realm of robotics, where precision and adaptability are paramount, the quest for accurate room impulse responses (RIRs) has long been a formidable challenge. Traditional methods, bound by the constraints of mathematical rigor and the demands of extensive measurements, falter when faced with the dynamic nature of real-world environments. These approaches are not only computationally burdensome but also lack the scalability necessary for navigating the complexities of our surroundings. Moreover, they often rely on assumptions that are too rigid for the unpredictable nature of practical applications.  Enter SoundNeRirF, a groundbreaking innovation that reimagines the prediction of RIRs through the power of neural fields. This method transcends the limitations of its predecessors by eschewing the need for prior knowledge about sound sources or the intricate details of room acoustics. Instead, SoundNeRirF draws upon the rich tapestry of data gathered from a robot's exploration of its environment, learning to predict the reverberant sound that would grace any spatial position from any other.  At the heart of SoundNeRirF lies a clever disentanglement of the RIR learning process from the nuances of sound prediction. This separation not only enhances its generalization capabilities but also empowers it to adapt to previously unheard sounds with ease. Additionally, we introduce a suite of regularization techniques designed to guide SoundNeRirF in the explicit learning of direct-path, specular reflection, and late reverberation—essential elements of room acoustics.  To validate our approach, we have compiled a diverse array of datasets, spanning both synthetic and real-world scenarios, which we are delighted to share with the community. Our findings reveal that SoundNeRirF not only meets but exceeds the performance of existing methods, paving the way for a new era of acoustic understanding in robotics."}
{"paper_id": "494", "abstract": "In the realm of sound, where melodies dance on the wind and chaos sometimes reigns, the quest to count the myriad voices of the living is both a fundamental need and a formidable challenge. This endeavor, known as sound counting, has long been overshadowed by its more celebrated counterpart in the visual realm—crowd counting. Yet, the intricacies of sound are far more complex, woven into the very fabric of our environment. The task of sound counting demands a method that can navigate the treacherous waters of temporal concurrence, spectral overlap, and the ever-present variance in loudness.  In this paper, we unveil a groundbreaking approach: the Dyadic Decomposition Network, or DyDecNet. This innovative architecture embarks on a journey of hierarchical dyadic decomposition, progressively refining the raw waveform into a robust time-frequency representation. Each step in this process is meticulously crafted to address the unique challenges of sound counting, employing an energy gain normalization module that ensures our learned representations remain resilient against the unpredictable nature of sound.  But we do not stop at architecture; we also introduce a suite of polyphony-aware metrics, designed to illuminate the intricacies of sound counting across diverse datasets. Through rigorous experimentation, we traverse the spectrum from real-world to synthetic, employing both cross-domain and self-synthesized datasets that push the limits of our approach.  Our findings reveal that DyDecNet not only excels in sound counting but does so with a grace that outshines existing state-of-the-art methods, particularly in the realm of highly polyphonic and cluttered environments. In this exploration, we not only advance the field of sound counting but also illuminate the path for future endeavors in the intricate world of auditory analysis."}
{"paper_id": "495", "abstract": "In the realm of mobile agents navigating the complexities of their surroundings, the quest for an efficient and accurate map is akin to a hero seeking a legendary artifact. Traditionally, these agents have relied on topological maps—simplified representations that capture the essence of their environment through a web of spatial relationships, much like a skilled artisan weaving together the threads of a tapestry. Yet, the creation of these maps often feels like a journey fraught with trials, as agents wander aimlessly, revisiting the same locales over and over, their progress slow and laborious.  Enter the Active Topological Mapping (ATM) framework, a beacon of innovation that transforms this narrative. By harnessing the power of imitation learning, ATM empowers agents to embark on strategic explorations, deftly selecting the most promising trajectories to chart their course. Once the agent has returned with its treasure trove of observations, ATM skillfully constructs a topological map, a vibrant representation of the environment that can be wielded for navigation with precision.  Our experiments reveal the prowess of ATM, showcasing its remarkable ability to maximize coverage and navigate with ease, all while operating in a metric-free feature space that is both lightweight and generalizable. In a world where every step counts, ATM stands as a testament to the potential of innovation, guiding agents toward a future of exploration and discovery."}
{"paper_id": "496", "abstract": "In the realm of artificial intelligence, the quest for systematic generalization has long been a formidable challenge, with most neural networks faltering under the weight of their own limitations. Yet, a glimmer of hope emerged with the advent of neural-symbolic methods, which sought to weave together the intricate tapestry of perception, syntax, and semantics. However, these approaches often proved cumbersome, shackled by the need for intricate design and domain-specific knowledge, leaving them ill-equipped to navigate the diverse landscapes of real-world applications.  Enter the Neural-Symbolic Recursive Machine (NSR), a groundbreaking creation designed to transcend these constraints. NSR embraces a modular architecture, each component imbued with its own inductive biases—equivariance and recursiveness—facilitating the progressive breakdown of input into manageable components, their composition, and the generation of meaningful outputs. At the heart of NSR lies the Grounded Symbol System (GSS), a representation that emerges organically from the training data, requiring no prior domain expertise.  To navigate the complexities of learning, we introduce a probabilistic framework and a novel deduction-abduction algorithm, meticulously crafted to harmonize the joint learning of perception, syntax, and semantics. Our evaluations span a trio of benchmarks, each spanning multiple splits that test the limits of systematic generalization across varied domains. The results are nothing short of remarkable: NSR sets new benchmarks, achieving perfect generalization on the SCAN and PCFG datasets, and significantly outpacing existing methods on HINT with an impressive 23% improvement.  Moreover, we explore NSR's potential in a machine translation task, illuminating its adaptability to practical applications. In this way, NSR not only pushes the boundaries of what is possible in artificial intelligence but also paves the way for a future where machines can truly learn and adapt with the grace of human intelligence."}
{"paper_id": "497", "abstract": "In the realm of Generative Adversarial Networks (GANs), the quest for high-quality image manipulation has led to a proliferation of sophisticated models, each claiming to enhance the art of inversion. Yet, a critical examination reveals a troubling truth: these models often excel at refining the lower frequency components of images, leaving the delicate high-frequency details, such as edges and textures, neglected. This oversight results in a disheartening loss of clarity and precision in the final outputs.  To address this challenge, we introduce a groundbreaking approach known as WaGI—Wavelet-based GAN Inversion. This innovative method delves into the frequency domain, employing a wavelet transform to dissect images into their low- and high-frequency sub-bands. By doing so, WaGI employs a dual strategy: first, it amplifies the loss associated with the high-frequency sub-bands, ensuring that these critical details are not overlooked; second, it facilitates a direct transfer of high-frequency features to the reconstructed image, preserving the integrity of the output.  Our experiments reveal that WaGI not only surpasses the current state-of-the-art in terms of inversion quality but also demonstrates remarkable resilience against various forms of noise. In a world where clarity is paramount, WaGI stands as a beacon of hope, restoring the lost intricacies of image manipulation."}
{"paper_id": "498", "abstract": "In the realm of video highlights detection (VHD), the prevailing methods often operate under the rigid constraints of a fixed training dataset and a predetermined number of highlight domains, all while adhering to the closed world assumption. This means that once the training data and domain labels are established, they remain static, presenting a significant barrier to adaptability and scalability. In the dynamic landscape of real-world applications, where new domains and data emerge continuously, this rigidity can stifle innovation and practical utility.  To address this challenge, we introduce a groundbreaking dataset, LiveFood, featuring over 5,100 high-quality gourmet videos, meticulously annotated across four distinct domains: cooking, eating, ingredients, and presentation. This rich resource serves as a vital foundation for the exploration of incremental VHD.  Building upon the strengths of the transformer encoder, we unveil a novel end-to-end model for incremental VHD, aptly named Global Prototype Encoding (GPE). GPE operates by learning adaptable and parameterized highlight and vanilla prototypes, enabling it to incrementally identify and classify frames within new highlight domains. Our extensive experiments reveal that GPE not only excels in performance, achieving an impressive average mAP of 84.22%, but also does so with remarkable efficiency, outpacing other state-of-the-art methods in the realm of incremental learning.  Through our work, we aim to illuminate the path for future research in incremental VHD, fostering a deeper understanding of the underlying principles and paving the way for practical applications in dynamic environments."}
{"paper_id": "499", "abstract": "In the realm of deep learning, the specter of gradient explosion looms large, often lurking in the shadows of deep neural networks that employ batch normalization and ReLU-like activation functions. While it is true that this phenomenon tends to diminish as training progresses, its presence during the early stages can wreak havoc, disrupting the delicate equilibrium among layers and ultimately undermining performance. In this exploration, we embark on a mathematical odyssey to unravel the intricate dance between batch normalization and the activation functions that precede it. Our findings reveal that the root of this instability lies in the interplay of the batch normalization coefficient and the variance of the activation function. Specifically, when the batch normalization coefficient surpasses a critical threshold—approximately 1.21 times the average of the activation variance across all layers—the conditions are ripe for gradient explosion to take hold. This insight not only clarifies the underlying mechanism but also opens the door to potential remedies, guiding us toward strategies that can mitigate this formidable challenge in the landscape of deep learning."}
{"paper_id": "500", "abstract": "In the realm of organic synthesis, the quest to craft a target molecule from the ground up is akin to a grand adventure, a journey fraught with the intricacies of chemical reactions. Enter Metro, our groundbreaking approach to retrosynthetic planning, a method that harnesses the power of attention and memory to navigate this complex landscape.   At its core, Metro reimagines the traditional template-based retrosynthetic planning, transforming it into a sophisticated search problem that embraces the dynamic nature of chemical synthesis. We introduce a novel reaction graph, a living tapestry woven from the threads of existing reactions in the database, where directed edges signify the flow of retrosynthetic transformations. Given a target molecule, we embark on a quest to uncover the most efficient routes, represented as reaction trees, within this graph.   To tackle the challenges posed by the vast and intricate space of potential routes, we employ a Transformer-based model enhanced with a memory module. This innovative design allows us to anchor our predictions in the context of the entire reaction tree, fostering a rich, multi-hop attention that considers the broader chemical landscape. The result? A significant leap forward, with Metro achieving an impressive 13.2% improvement in top-1 accuracy over traditional Transformer models in retrosynthetic planning.  But we don’t stop there. We’ve also crafted a new benchmark, replete with 124,869 reaction trees sourced from the esteemed USPTO dataset, to serve as the foundation for our evaluations. Join us on this journey as we redefine the boundaries of retrosynthetic planning, illuminating the path to more efficient and effective synthesis."}
{"paper_id": "501", "abstract": "In the vast expanse of our exploration, we unveil a novel framework, one that reimagines the way we navigate the complexities of the world. Picture, if you will, a method that carves the vast landscape into manageable fragments, each a local model crafted through the art of online clustering. When the agent encounters a region that defies its current understanding, a fragmentation event occurs, birthing a new local model from the remnants of the old. This innovative approach not only streamlines memory but also accelerates our journey through the unknown.  In our quest, we tackle two formidable challenges: first, the intricate task of spatial exploration within procedurally-generated environments; second, the exploration of diverse, heterogeneous game scenarios through the lens of reinforcement learning. The results are striking: our method, FarMap, demonstrates a remarkable reduction in online memory usage and an impressive decrease in wall-clock time, all while achieving superior performance. Furthermore, in the realm of reinforcement learning, FarCuriosity adeptly navigates the complexities of heterogeneous environments, effectively mitigating the pernicious effects of catastrophic forgetting.  With these advancements, we stand on the precipice of a new understanding, where exploration is not just a journey but a dance of discovery, facilitated by the power of our innovative framework."}
{"paper_id": "502", "abstract": "In the realm of image processing, the quest for a reliable conversion model from infrared to visual has long been fraught with challenges, often hindered by the absence of suitable training datasets and the complexities of real-world scene representations. In this study, we embark on a groundbreaking journey, leveraging the KAIST-MPD dataset—a treasure trove of paired visual and infrared images that illuminate various scenes.   Our approach is both innovative and meticulous. We introduce a novel multi-scale encoder-decoder network, intricately designed with U-shaped architecture and meticulously crafted using the Keras high-level neural network API, built upon the robust TensorFlow framework. This network employs a series of 3×3 convolutional layers, each enhanced by batch normalization and ReLU activation functions, ensuring that our model not only learns effectively but also adapts gracefully to the nuances of the data.  To refine our conversion model, we propose two structure-sensitive loss functions, meticulously crafted to complement the traditional L1 loss and the adversarial loss. These new additions serve to bolster the structural integrity of the generated images, addressing a critical shortcoming often overlooked in conventional training methodologies. The results of our endeavor are nothing short of remarkable. Our model achieves an impressive structural similarity (SSIM) score of 0.92 and an image quality assessment (IQA) score of 4.32, outshining all existing methods in the infrared-to-visual conversion landscape. In this way, we not only push the boundaries of what is possible but also illuminate a path forward for future research in this exciting field."}
{"paper_id": "503", "abstract": "In the intricate tapestry of life, proteins stand as the architects of biological function, each one a masterpiece woven from the delicate interplay of amino acids. Yet, amidst their beauty lies a shadow: the specter of disease, often rooted in the misfolding of these essential molecules. To combat this, we embark on a quest to harness the power of computation, seeking to generate novel protein structures that could illuminate the path to new therapies.   In this endeavor, we unveil a groundbreaking approach—a generative model that directly navigates the angles of protein backbones, transcending traditional methods that rely on cumbersome post-processing of indirect representations. At the heart of our innovation lies a denoising diffusion probabilistic model, elegantly parameterized by a transformer, which learns to sample from the intricate distribution of inter-residue angles that define protein conformations.  Our model undergoes rigorous testing, undergoing a series of validations that reveal its prowess. We demonstrate its ability to produce realistic protein backbones, rich with structural motifs that are not only diverse but also amenable to design. The results are striking: our generated backbones exhibit a remarkable naturalness, with a distribution of backbone dihedral angles that mirrors the complexity of the Rosetta training set. Furthermore, we observe a frequency of structural motifs that aligns with our expectations, showcasing the model's capacity to replicate the inherent patterns of protein architecture.  In a leap forward, we also introduce a simple scoring function that allows us to filter our samples, yielding an impressive hit rate of 60% for native-like structures when compared to a comprehensive library of experimentally determined protein structures. This achievement not only validates our approach but also opens the door to the discovery of novel protein designs, poised to reshape our understanding of biology and medicine."}
{"paper_id": "504", "abstract": "In the realm of machine learning, the quest for generalization often feels like navigating an uncharted landscape, where the intricacies of inductive biases remain shrouded in mystery. In this paper, we embark on a journey to illuminate this elusive concept through the lens of information theory, forging a new path to quantify the inductive bias complexity of learning tasks.   We introduce a groundbreaking framework that reimagines tasks as distinct islands within a vast ocean of possibilities, each defined by a unique combination of features and target values. At the heart of our exploration lies a formal definition of inductive bias complexity, measured in bits, which captures the essence of the constraints that govern a task. This measure reveals the fraction of the entire hypothesis space that aligns with these constraints, allowing our algorithm to deftly estimate the inductive bias complexity of various learning challenges.  Through our quantitative analysis, we unveil a startling revelation: the widely-played game of CartPole in a 2D environment demands far greater inductive bias than the celebrated Atari game of Breakout—despite Breakout’s reputation for greater generalization difficulty. Our findings extend to the realms of meta-learning and reinforcement learning, shedding light on the intricate interplay between task characteristics and the demands of generalization.  In this endeavor, we not only advance our understanding of inductive biases but also provide a robust algorithm capable of quantifying the generalization difficulty across a diverse array of learning tasks. Join us as we unravel the complexities of machine learning, one step at a time."}
{"paper_id": "505", "abstract": "In the realm of deep generative modeling, a prevailing assumption has emerged: that the latent representations learned from these models inherently encode rich semantics, allowing for the precise editing of data through strategic traversal in the latent space. Yet, the validity of this assumption remains shrouded in ambiguity. In this exploration, we embark on a journey to scrutinize the disentanglement of the latent spaces yielded by three prominent pretrained deep generative models, delving into their interpretations across two distinct domains—molecular graphs and point clouds. Our empirical investigations reveal a disheartening truth: these latent representations fall short of the pristine disentanglement we had hoped for.  Armed with this insight, we introduce GraphCG, a versatile and adaptable framework designed for unsupervised graph controllable generation. At its core, GraphCG seeks to unravel the tangled threads of the latent space by learning semantic directions through the maximization of their mutual information. In doing so, it empowers us to navigate the latent landscape with newfound precision, facilitating the editing of graph structures in a manner that is both flexible and task-agnostic.  To validate our approach, we present a series of qualitative and quantitative evaluations on both molecular graphs and point clouds. The results are compelling, showcasing GraphCG's superior performance and enhanced controllability over existing baselines. In this endeavor, we not only advance the capabilities of deep generative modeling but also illuminate a path forward in the quest for more nuanced and effective data manipulation."}
{"paper_id": "506", "abstract": "In the realm of machine learning, where the quest for accuracy often feels like a hero's journey, we find ourselves at a crossroads. The traditional path of model optimization, focused on minimizing error rate (ER), can sometimes lead to a perilous outcome: an increase in negative flip rate (NFR). These negative flips, those instances where a model confuses the old with the new, pose a significant challenge, particularly in high-stakes environments where human trust is paramount.  In this paper, we embark on a deeper exploration of the ensembles' role in the battle against NFR. We unveil a novel framework that reimagines the ensemble as a diverse council of experts, each with their own unique strengths. Our findings reveal that the power of these ensembles lies not only in their ability to mitigate NFR but also in their potential to enhance the accuracy of individual models through a process we call \"expert voting.\"  But we do not stop there. Drawing inspiration from the principles of cooperative game theory, we introduce a groundbreaking approach: the NFR Minimax Entropy (NFR-ME) algorithm. This method seeks to maximize the minimum entropy of NFR across all possible pairs of models, effectively forging a path toward a more harmonious coexistence between old and new.  Through rigorous experimentation, we demonstrate that our NFR-ME algorithm not only surpasses the state-of-the-art in reducing NFR but also does so without sacrificing accuracy. In a world where every decision matters, we are proud to present a method that empowers model update strategies, ensuring that the journey forward is not just a step, but a leap into a brighter future."}
{"paper_id": "507", "abstract": "In the realm of optimal transport, a common practice is to tackle the same transport problem repeatedly, each iteration fraught with the computational burdens of solving an optimization conundrum from scratch. This approach, while necessary, often overlooks the intricate web of shared structure and information that binds these successive challenges together. To illuminate this overlooked potential, we delve into the concept of amortized optimization, crafting a novel framework we call Meta Optimal Transport (Meta OT). This innovative approach learns to predict the solution to an optimal transport problem based on the very measures themselves.   In our exploration, we first establish a discrete Meta OT model, where we train a neural network to approximate the optimal coupling between two discrete measures. The results are striking: our model not only accelerates the process of solving the unregularized optimal transport problem but also does so with a reduced number of Sinkhorn iterations compared to traditional methods. We then extend our reach to a continuous setting, applying Meta OT to the regularized optimal transport problem between a 2D Gaussian and various 1D Gaussian measures. Here, we demonstrate that our approach can swiftly generate optimal couplings, all while incurring a fraction of the computational cost typically associated with standard solvers.  Through these experiments, we unveil the remarkable efficiency and effectiveness of Meta OT, showcasing how it can dramatically cut down the time and computational resources needed to solve optimal transport problems. In doing so, we open new doors for future research and application, inviting others to explore the potential of this approach in their own endeavors."}
{"paper_id": "508", "abstract": "In the ever-evolving landscape of deep learning, the attention mechanism has emerged as a beacon of efficiency, wielding the power to tackle long-range dependencies with remarkable grace. Yet, as we delve deeper, we uncover a critical flaw in its design—an inefficiency that arises from the necessity of attending to every single element within a sequence, a burden that becomes increasingly cumbersome as the length of the sequence grows. This limitation has often stifled the potential of attention mechanisms in practical applications, particularly in the realm of edge inference environments where computational resources are scarce.  Enter the Neural Attention Memory (NAM), a groundbreaking approach that reimagines the very essence of attention as a robust external memory for neural networks. With NAM, we redefine the way information is stored and retrieved, employing a simple yet elegant structure that multiplies queries with keys to generate memory addresses. This innovative design not only streamlines the process of attention but also empowers NAM to learn the art of writing and reading from a vast, infinite memory matrix through differentiable means.  But NAM does not merely stop at efficiency; it offers a versatile architecture that can be seamlessly integrated as a plug-in module into any deep neural network, enhancing its capabilities. We unveil two compelling applications of NAM: first, as a memory-enhanced Transformer that excels in long-range sequence tasks, and second, as a memory-augmented neural network tailored for algorithmic tasks, particularly those demanding compositional generalization.  Our findings reveal that NAM possesses the ability to generalize effectively across a spectrum of algorithmic challenges, outshining traditional memory-augmented networks like DNC. In a world where resources are precious and computational demands are high, NAM stands as a beacon of innovation, ready to illuminate the path forward in the realm of neural networks."}
{"paper_id": "509", "abstract": "In the realm of machine learning, the quest for large-scale datasets often collides with the pressing need for data privacy and ethical considerations. To navigate this intricate balance, we unveil a groundbreaking approach: Multi-attribute Selective Suppression, or MaSS. This innovative framework empowers the precise suppression of specific attributes within multi-attribute datasets, all while safeguarding the integrity of other, non-sensitive features.  At its core, MaSS harnesses the power of adversarial training, employing a multi-task loss function that deftly optimizes the suppression of targeted attributes. Additionally, it incorporates a feature reconstruction loss, which acts as a safeguard, ensuring that the non-targeted features remain robust and intact. This dual approach not only enhances the suppression of sensitive information but also fortifies the preservation of the dataset's utility for downstream tasks.  Our experiments, conducted across a diverse array of image, audio, and video datasets, reveal MaSS's remarkable efficacy. The results demonstrate its ability to suppress a variety of attributes—ranging from demographic to semantic—while maintaining the overall utility of the data. In this way, MaSS not only advances the principles of data privacy but also champions the continued growth of machine learning through the responsible use of data."}
{"paper_id": "510", "abstract": "In the realm of machine learning, where the quest for understanding often collides with the shadows of complexity, weakly-supervised object localization (WSOL) emerges as a beacon of hope. This task seeks to illuminate the identities of objects within images, relying solely on broad strokes of class labels, a challenge that stands in stark contrast to the meticulously annotated datasets favored by traditional methods. In this paper, we embark on an exploration of WSOL through the lens of several prominent heatmap-based explainable artificial intelligence (XAI) techniques, including Class Activation Mapping (CAM), GradCAM, Guided Backpropagation (GBP), and DeepLift.  Our journey reveals that while these methods, when wielded with the right touch, can rival the prowess of CAM, they often fall short of achieving the coveted maximum box accuracy (MaxBoxAcc) without the aid of WSOL training—a process that can sometimes undermine the predictive prowess of the model. However, we uncover a path forward: by integrating CAM-like concepts into the fabric of existing XAI methodologies, we can extract localized heatmaps that surpass the original CAM's performance, all without the need for WSOL training.  To further enhance our localization capabilities, we introduce a novel approach: Neural Backed Decision Tree (NBDT) training. This innovative technique not only sharpens our localization skills but also maintains the integrity of predictive accuracy, paving the way for a more harmonious relationship between understanding and performance in the realm of WSOL."}
